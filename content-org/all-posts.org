#+hugo_base_dir: ../
#+options: author:nil
* DONE Setting up rgee :rgee:R:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: setting-up-rgee
:END:

**  Introduction

From the [[https://github.com/r-spatial/rgee][rgee github page]]: "rgee is an R binding package for calling Google Earth Engine API from within R. Various functions are implemented to simplify the connection with the R spatial ecosystem."

This guide assumes use of RStudio on a Mac, but I personally use Emacs with ESS and found it to work wonderfully. Any Unix based system should work similarly. Windows should theoretically work by following the below, but more work might be required and I haven't tested it.

** Prerequisites

- R and RStudio (or other IDE)
- Google Earth Engine account.
  - Create a GEE project to work in.
- A healthy mindset ðŸ˜Š

** Installation

Install rgee, geojsonio and miniconda.

#+begin_src R
install.packages('rgee')
install.packages('reticulate')
install.packages('geojsonio')
reticulate::install_miniconda()
#+end_src

** Setup

Load the packages.

#+begin_src R
library(rgee)
library(geojsonio)
library(reticulate)
#+end_src

Install dependencies and double check to make sure everything is up to date.

#+begin_src R
rgee::ee_install()
rgee::ee_install_upgrade()
#+end_src

By this point, you should be ready to initialize rgee. To double check everything is ready, run a
#+begin_src R
ee_check()
#+end_src
to make sure. /Note: If the previous command complains about an argument being of length zero, it should be fine to ignore it and carry on./


** Initializing
If you haven't already, you will need to create a new project to work in. This process is semi annoying if you haven't already done it before, full disclaimer.

Navigate over to [[https://code.earthengine.google.com][the GEE code editor]] and click on your profile picture in the top right. Click "Register a new Cloud Project". Assuming this is correct, click "Register a Noncommercial or Commercial project" and then select "Unpaid usage". Select the relevent project type in the dropdown menu.

On the next screen, choose "Create a new Google Cloud Project". You can leave the Organization field blank, but you will need to at the least choose a project ID. I usually name my projects with the *ee-username-rgee-#*, where username is my username and # is a number. Note that creating the project can take a while. Don't refresh the page, as you will be forced to go through the above process again.

Once you've confirmed your project's information, you will be redirected to the GEE online code editor, where you can close the tab.

Moving back into the IDE, we can now initialize rgee.
#+begin_src R
ee_Initialize()
#+end_src

This should launch a page in your web browser where you can log in and select the project you created to link to rgee. Make sure to choose "Select an existing project" and select it.

If that didn't work, or threw you an error, don't panic. I had enormous amounts of trouble getting rgee to initialize properly. If this is the case for you, you can instead run the below two commands, which does the same thing.

/Note that you will need to replace the project name with your own./
#+begin_src R
ee$Authenticate(auth_mode='localhost')
ee$Initialize(project='YOUR-PROJECT-NAME')
#+end_src

Optionally, check your connectivity to GEE to see if everything is setup correctly.
#+begin_src R
ee$String('Hello from the Earth Engine servers!')$getInfo()
#+end_src

If one of those methods worked, pop the champagne.

*At the start of every new R session where you want to use rgee, you will need to load and then initialize the package in order to use it.*

This should look something like this

#+begin_src R
library(rgee)
ee$Authenticate(auth_mode='localhost')
ee$Initialize(project='YOUR-PROJECT-NAME')
#+end_src

Remember to change the project name to the one you created earlier.

** Examples
*** Surface water occurrence
In this example, rgee is used to visualize global surface water occurrence using the JRC Global Surface Water dataset.

/Load and initialize rgee first!/
#+begin_src R
# Loads the dataset from JRC
gsw <- ee$Image("JRC/GSW1_1/GlobalSurfaceWater")
occurrence <- gsw$select("occurrence")

# Defines params to show surface water
VIS_OCCURRENCE <- list(
  min = 0,
  max = 100,
  palette = c("red", "blue")
)

# Makes a mask with said params
VIS_WATER_MASK <- list(
  palette = c("white", "black")
)

# Creates another mask that only shows areas w/ 90% water occurance
water_mask <- occurrence$gt(90)$selfMask()

# Sets the center of the map to Douglas County
Map$setCenter(-95.3, 38.91, 11)

# Adds both masks to the map
Map$addLayer(occurrence$updateMask(occurrence$divide(100)), VIS_OCCURRENCE, "Water Occurrence (1984-2018)") +
Map$addLayer(water_mask, VIS_WATER_MASK, "90% occurrence", FALSE)
{% endhighlight %}

#+end_src
*** May 28th 2019 Tornado

In this example, rgee is used to view the damage path from the 2019 EF4 tornado that touched down in central Douglas County.

/Load and initialize rgee first!/
#+begin_src R

# Defines an area around Douglas County.
aoi <- ee$Geometry$Rectangle(c(-95.3, 38.85, -95.22, 38.91))

# Defines the dates we are interested in.
start_date <- '2019-05-28'
end_date <- '2019-06-01'
pre_event_date <- '2019-05-20'

# Load Sentinel-2 data for said dates.
s2_collection <- ee$ImageCollection('COPERNICUS/S2')$
  filterDate(start_date, end_date)$
  filterBounds(aoi)

# Get the least cloudy image from the post-event period.
post_event_image <- s2_collection$sort('CLOUDY_PIXEL_PERCENTAGE')$first()

# Define params for said image.
viz_params <- list(
  bands = c('B4', 'B3', 'B2'),
  min = 0,
  max = 3000,
  gamma = 1.4
)

# Add the post-event image to the map.
Map$centerObject(aoi, 12)  # Zoom in to level 12 for better detail
Map$addLayer(post_even  t_image, viz_params, 'Post-Event Sentinel-2 Image')

# Load pre-event data for comparison.
pre_event_image <- ee$ImageCollection('COPERNICUS/S2')$
  filterDate(pre_event_date, start_date)$
  filterBounds(aoi)$
  sort('CLOUDY_PIXEL_PERCENTAGE')$first()


# Calculate NDVI for pre and post tornado.
pre_ndvi <- pre_event_image$normalizedDifference(c('B8', 'B4'))
post_ndvi <- post_event_image$normalizedDifference(c('B8', 'B4'))

# Find difference.
ndvi_diff <- post_ndvi$subtract(pre_ndvi)

# Define params for NDVI difference.
ndvi_viz_params <- list(min = -0.5, max = 0.5, palette = c('red', 'yellow', 'green'))

# Add NDVI diff. layer to map!
Map$addLayer(ndvi_diff, ndvi_viz_params, 'NDVI Difference')
{% endhighlight %}
#+end_src

* DONE Using variables in rgee :rgee:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: using-variables-in-rgee
:END:
** Introduction

Google Earth Engine provides access to a bunch of geospatial datasets including satellite imagery, climate data and land cover classifications. These datasets, known as variables, are used to perform geospatial analyses.

** Calling variables
/Load and initialize rgee first!/

Define an area that you want to visualize. The easiest way of doing this is to define a rectangle with coordinates.

#+begin_src R
aoi <- ee$Geometry$Rectangle(c(-120.4, 34.5, -119.4, 35.5))
#+end_src

In this example, I'll use the MODIS land cover datasets.

#+begin_src R
landcover <- ee$ImageCollection("MODIS/061/MCD12Q1")$first()$select("LC_Type1")
#+end_src

Set some visualization parameters to control how the data is displayed.

#+begin_src R
landcover_viz <- list(
  min = 1,
  max = 17,
  palette = c("05450a", "086a10", "54a708", "78d203", "009900",
              "c6b044", "dcd159", "dade48", "fbff13", "b6ff05",
              "27ff87", "c24f44", "a5a5a5", "ff6d4c", "69fff8",
              "f9ffa4", "1c0dff")
)
#+end_src

Center the map on the area we are interested in, and add in the land cover layer using the parameters we defined above.

#+begin_src R
Map$centerObject(aoi,8)
Map$addLayer(landcover, landcover_viz, "Land Cover :)")
#+end_src
* DONE Making maps of variables with rgee :rgee:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: Making-maps-of-variables-with-rgee
:END:
** Introduction

Raw data often needs to be transformed in order to do anything useful with it. Typically, transforming variables in GEE involves manipulating raw bands of imagery to create products like NDVI and EVI, or performing math operations with multiple datasets.

*** Dividing EVI by Precipitation
In this example, EVI is being divided by precipitation data for Kansas, and the result is mapped.

/Load and initialize rgee first!/
#+BEGIN_SRC R
library(rgee)
ee_Initialize()

# Define an area of interest (AOI) over Kansas
aoi <- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0))

# Load the Sentinel-2 image collection and calculate EVI
s2_collection <- ee$ImageCollection("COPERNICUS/S2")$
  filterDate('2020-06-01', '2020-08-31')$
  filterBounds(aoi)$
  map(function(image) {
    evi <- image$expression(
      '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',
      list('NIR' = image$select("B8"), 'RED' = image$select("B4"), 'BLUE' = image$select("B2"))
    )$rename("EVI")
    return(image$addBands(evi))
  })
evi_image <- s2_collection$select("EVI")$mean()$clip(aoi)

# Visualize EVI to ensure it's calculated correctly
evi_viz <- list(
  min = -1,
  max = 1,
  palette = c("brown", "yellow", "green")
)
Map$setCenter(-98.35, 38.5, 6)
Map$addLayer(evi_image, evi_viz, "EVI")

# Load the TerraClimate PPT (precipitation) dataset
ppt_dataset <- ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE")$
  filterDate('2020-01-01', '2020-12-31')$
  select("pr")$
  mean()$
  clip(aoi)

# Visualize PPT to ensure it's loaded correctly
ppt_viz <- list(
  min = 0,
  max = 2000,
  palette = c("blue", "white", "green")
)
Map$addLayer(ppt_dataset, ppt_viz, "Precipitation")

# Ensure the datasets align perfectly for each pixel
evi_resampled <- evi_image$reproject(crs = ppt_dataset$projection(), scale = 1000)
ppt_resampled <- ppt_dataset$reproject(crs = evi_image$projection(), scale = 1000)

# Divide EVI by PPT
evi_ppt_ratio <- evi_resampled$divide(ppt_resampled)

# Define visualization parameters for the ratio
evi_ppt_viz <- list(
  min = 0,
  max = 0.1,
  palette = c("blue", "white", "red")
)

# Add the EVI/PPT ratio layer
Map$addLayer(evi_ppt_ratio, evi_ppt_viz, "EVI/PPT Ratio")

#+END_SRC

*** Breakdown

**** Define the AOI, the state of Kansas.

#+BEGIN_SRC R
aoi <- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0))
#+END_SRC

**** Load and Filter Sentinel-2 Data

Next, we load the Sentinel-2 image collection, filter it for the summer months (June to August 2020), and calculate EVI for each image. EVI values are then averaged and clipped only to our AOI.

#+BEGIN_SRC R
s2_collection <- ee$ImageCollection("COPERNICUS/S2")$
  filterDate('2020-06-01', '2020-08-31')$
  filterBounds(aoi)$
  map(function(image) {
    evi <- image$expression(
      '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',
      list('NIR' = image$select("B8"), 'RED' = image$select("B4"), 'BLUE' = image$select("B2"))
    )$rename("EVI")
    return(image$addBands(evi))
  })
evi_image <- s2_collection$select("EVI")$mean()$clip(aoi)
#+END_SRC

**** First mapping of EVI

This is to make sure the current values are correct and being visualized correctly. I had a lot of trouble with this example in particular, so I am redundantly checking work as we go.

#+BEGIN_SRC R
evi_viz <- list(
  min = -1,
  max = 1,
  palette = c("brown", "yellow", "green")
)
Map$setCenter(-98.35, 38.5, 6)
Map$addLayer(evi_image, evi_viz, "EVI")
#+END_SRC

**** Loading precip data

We load precip data from TerraClimate, filter it for the year 2020, average values, and clip them.

#+BEGIN_SRC R
ppt_dataset <- ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE")$
  filterDate('2020-01-01', '2020-12-31')$
  select("pr")$
  mean()$
  clip(aoi)
#+END_SRC

**** Visualize PPT to make sure it's correct

Again, I am visualizing the precipitation data to make sure it looks correct.

#+BEGIN_SRC R
ppt_viz <- list(
  min = 0,
  max = 2000,
  palette = c("blue", "white", "green")
)
Map$addLayer(ppt_dataset, ppt_viz, "Precipitation")
#+END_SRC

**** Make sure data is aligned

Before actually performing any operations on the data, making sure that both datasets are aligned correctly is important. Here I'm reprojecting both sets to the same scale and resolution.

#+BEGIN_SRC R
evi_resampled <- evi_image$reproject(crs = ppt_dataset$projection(), scale = 1000)
ppt_resampled <- ppt_dataset$reproject(crs = evi_image$projection(), scale = 1000)
#+END_SRC
**** Transform the data

Dividing the EVI by the precip to calculate the ratio.

#+BEGIN_SRC R
evi_ppt_ratio <- evi_resampled$divide(ppt_resampled)
#+END_SRC

**** Define viz params for mapping the new ratio


#+BEGIN_SRC R
evi_ppt_viz <- list(
  min = 0,
  max = 0.1,
  palette = c("blue", "white", "red")
)
Map$addLayer(evi_ppt_ratio, evi_ppt_viz, "EVI/PPT Ratio")
#+END_SRC
* DONE Exporting data to a CSV with rgee :rgee:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: Exporting-data-to-a-csv-with-rgee
:END:
** Introduction

In general, exporting data to a .csv with rgee is pretty easy. The general gist of the process is:
- Define the area or points you are interested in
- Filter data
- Convert the results to a list, and
- Export to a csv.

** Example
/Make sure to load and initialize rgee first!/
#+BEGIN_SRC R
# Define an AOI over Kansas
aoi <- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0))

# Define sample points in the area
points <- ee$FeatureCollection(c(
  ee$Feature(ee$Geometry$Point(-98.5795, 39.8283), list(label = "1")),
  ee$Feature(ee$Geometry$Point(-97.5795, 38.8283), list(label = "2")),
  ee$Feature(ee$Geometry$Point(-96.5795, 37.8283), list(label = "3"))
))

# Grab an image from Sentinal 2 and calculate NDVI
s2_collection <- ee$ImageCollection("COPERNICUS/S2")$
  filterDate('2020-06-01', '2020-06-30')$
  filterBounds(aoi)$
  map(function(image) {
    ndvi <- image$normalizedDifference(c("B8", "B4"))$rename("NDVI")
    return(image$addBands(ndvi))
  })
ndvi_image <- s2_collection$select("NDVI")$mean()$clip(aoi)

# Grab NDVI values at the sample points
ndvi_values <- ndvi_image$reduceRegions(
  collection = points,
  reducer = ee$Reducer$mean(),
  scale = 30
)

# Convert the result to a list and then to a data frame
ndvi_list <- ndvi_values$getInfo()$features
ndvi_df <- do.call(rbind, lapply(ndvi_list, function(x) data.frame(
  label = x$properties$label,
  NDVI = x$properties$mean,
  lon = x$geometry$coordinates[1],
  lat = x$geometry$coordinates[2]
)))

# Save the data frame as a CSV
write.csv(ndvi_df, "ndvi_values_hello.csv", row.names = FALSE)
#+END_SRC

* DONE Getting data from AppEEARS and NOAA :rgee:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: Getting-data-from-AppEEARS-and-NOAA
:END:


** Data types (link to method of gathering)
- [[MAT][MAT (Mean Annual Temperature)]]
  - Average yearly temperature.
- [[MAP][MAP (Mean Annual Precipitation)]]
  - Average yearly precipitation.
- [[GPP][GPP (Gross Primary Productivity)]]
  - Total amount of energy captured by plants. Does not account for respiration losses.
- [[NPP][NPP (Net Primary Productivity)]]
  - Amount of energy that remains after plants have used some of the captured energy for their own respiration. Actual amount of new biomass that is available for consumption by other critters. NPP = GPP - Respiration
- [[PET][PET (Potential Evapotranspiration)]]
  - Amount of water that would be evaporated and transpired by vegetation if there was sufficient water available. Atmospheric demand for water.
- [[AET, ET][AET, ET (Actual Evapotranspiration)]]  - Actual amount of water that is evaporated from soil and transpired by vegetation. Less than or equal to PET. Depends on availability of water.
- [[DI][DI (Dryness Index)]]
  - PET / MAP
- [[EP][EP (Evaporation Potential)]]
  - 1 - (PET /MAP)
** Sites
Data was gathered from multiple sites, sorted with a RegionName, SiteName, and Pit. It's important that the Pit is unique.

*Note*: Although the majority of data sources were the same, there are sites where alternate sources were used. See footnotes.

| RegionName            | SiteName        | Pit          |
|-----------------------+-----------------+--------------|
| Calhoun               | R7              | R7P2         |
| Calhoun               | R2              | R2P1         |
| Calhoun               | R7              | R7P1         |
| Calhoun               | R8              | R8P1         |
| Calhoun               | R8              | R8P2.5       |
| Calhoun               | R8              | R8P2         |
| Calhoun               | R1              | R1C2         |
| Calhoun               | R1              | R1C3         |
| Calhoun               | R2              | R2H1         |
| Calhoun               | R7              | R7H1         |
| Calhoun               | R7              | R7H2         |
| Calhoun               | R8              | R8H1         |
| Calhoun               | R8              | R8H2.5       |
| Calhoun               | R8              | R8H2         |
| Luquillo[fn:ElVerde]       | ElVerde         | ElVerdeM     |
| Luquillo[fn:ElVerde]       | ElVerde         | ElVerdeR     |
| Luquillo[fn:ElVerde]       | ElVerde         | ElVerdeT     |
| Luquillo[fn:Icacos]       | Icacos          | IcacosM      |
| Luquillo[fn:Icacos]       | Icacos          | IcacosR      |
| Luquillo[fn:Icacos]       | Icacos          | IcacosT      |
| Catalina[fn:Catalina]      | MixedCon        | MC_M         |
| Catalina[fn:Catalina]      | MixedCon        | MC_R         |
| Catalina[fn:Catalina]      | MixedCon        | MC_T         |
| Catalina[fn:Catalina]      | BigelowDesert   | B2D_M        |
| Catalina[fn:Catalina]      | BigelowDesert   | B2D_R        |
| Catalina[fn:Catalina]      | BigelowDesert   | B2D_T        |
| ReynoldsCr[fn:ReynoldsCr]  | NorthBasalt     | NB_R         |
| ReynoldsCr[fn:ReynoldsCr]  | NorthBasalt     | NB_T         |
| ReynoldsCr[fn:ReynoldsCr]  | NorthLoess      | NL_T         |
| ReynoldsCr[fn:ReynoldsCr]  | SWBasalt        | SWB_M        |
| ReynoldsCr[fn:ReynoldsCr]  | SWBasalt        | SWB_T        |
| ReynoldsCr[fn:ReynoldsCr]  | SWLoess         | SWL_T        |
| SouthernSierra[fn:SJER]   | SJER            | SJER_M       |
| SouthernSierra[fn:SJER]   | SJER            | SJER_R       |
| SouthernSierra[fn:SJER]   | SJER            | SJER_T       |
| DukeFarm              | DukeFarm        | DFPasture    |
| EKS                   | Ottawa          | EKSAgri      |
| EKS                   | Welda           | EKSNative    |
| EKS                   | Welda           | EKSPostAg    |
| KNZ                   | KNZ             | KNZNative    |
| KNZ                   | KNZ             | KNZAgri      |
| KNZ                   | KNZ             | KNZPostAg    |
| HAY                   | HAY             | HAYNative    |
| HAY                   | HAY             | HAYAgri      |
| HAY                   | HAY             | HAYPostAg    |
| TRB                   | TRB             | TRBNative    |
| TRB                   | TRB             | TRBAgri      |
| TRB                   | TRB             | TRBAgriIrrig |
| TRB                   | TRB             | TRBPostAg    |
| FRESCC                | CC1             | CC1_2020     |
| FRESCC                | CC2             | CC2_2020     |
| FRESCC                | CC2             | CC2_2022     |
| FRESCC                | CC3             | CC3_2021     |
| FRESCC                | CC3             | CC3_2022     |
| FRESCC                | CC4             | CC4_2021     |
| FRESCC                | CC5             | CC5_2021     |
| Konza                 | GrassyToe       | GrToeN01B    |
| Konza                 | WoodyToe        | WdToeN04D    |
| Konza                 | GrassyBackslope | GrBackslN01B |
| Konza                 | WoodyBackslope  | WdBackslN04D |
| Konza                 | GrassySummit    | GrSummN01B   |
| Konza                 | WoodySummit     | WdSummN04D   |
| HJAndrews[fn:HJAndrews]    | WS01            | NF_Y_A       |
| HJAndrews[fn:HJAndrews]    | WS01            | SF_Y_A       |
| HJAndrews[fn:HJAndrews]    | WS02            | NF_O_A       |
| HJAndrews[fn:HJAndrews]    | WS02            | SF_O_A       |
| HJAndrews[fn:HJAndrews]    | WS03            | NF_O_A       |
| HJAndrews[fn:HJAndrews]    | WS03            | NF_Y_A       |
| HJAndrews[fn:HJAndrews]    | WS03            | SF_O_A       |
| HJAndrews[fn:HJAndrews]    | WS03            | SF_Y_A       |
| Alps                  | Glacier         | Alps1        |
| Alps                  | GlacierRidge    | Alps2        |
| Alps                  | Limestone       | Alps3        |
| Alps                  | Gneiss          | Alps5        |
| Alps                  | Alluvial        | Alps6        |
| NH                    | ThompsonPasture | NH_TP        |
| NH                    | ThompsonForest  | NH_TF        |
| NH                    | OrganicPasture  | NH_OP        |
| NH                    | OrganicForest   | NH_OF        |
| SouthernSierra[fn:PROV304] | Providence      | PROV304_R    |
| SouthernSierra[fn:PROV304] | Providence      | PROV304_M    |
| SouthernSierra[fn:PROV304] | Providence      | PROV304_T    |
| RCEW                  | RCEW_OC         | RCEW_OC      |
| RCEW                  | RCEW_OJ         | RCEW_OJ      |
| RCEW                  | RCEW_OS         | RCEW_OS      |
| RCEW                  | RCEW_YC         | RCEW_YC      |
| RCEW                  | RCEW_YJ         | RCEW_YJ      |
| RCEW                  | RCEW_YS         | RCEW_YS      |

[fn:ElVerde] Precipitation and temperature data for El Verde pits were gathered from [[https://luquillo.lter.network/long-term-datasets/][Luquillo LTER]]; "[[https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-luq&identifier=184&revision=185265][Field Station Air temperature from automatic sensor]]" and "[[https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-luq&identifier=14&revision=470060][Rainfall at El Verde Field Station]]", from 2010-2023. MAT data is viewable and automatically averaged with the "Explore data" button, but MAP data needs to be downloaded, manually added and averaged.

[fn:Icacos] Temperature data from the El Verde site was used. Precipitation data was pulled from [[https://www.ncei.noaa.gov/maps/annual/][NCEI at NOAA]].

[fn:Catalina] Precipitation and temperature data for MC and B2D pits were gathered from Oregon State University's PRISM climate data base.

[fn:ReynoldsCr] Precipitation and temperature data for NorthBasalt and NorthLoess pits were gathered from [[https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2018WR023063][Warming Alters Hydrologic Heterogeneity: Simulated Climate Sensitivity of Hydrology-Based Microrefugia in the Snow-to-Rain Transition Zone]], Table 1. NL_T is associated with Aspen, and all other pits were associated with Low sage.

[fn:SJER] Precipitation and temperature data were gathered from [[https://www.hydroshare.org/resource/d915275953c94b298b00872d98559e64/][Hydroshare]], from 2010-2018. Data is taken hourly, so it was summed and averaged across years. Data from 2018 was excluded from the precipitation average because it was erroneous. For temperature, TACTUAL was used in the average.

[fn:HJAndrews] Precipitation and temperature data for HJAndrews pits were gathered from [[https://andrewsforest.oregonstate.edu/sites/default/files/lter/pubs/webdocs/reports/decomp/study_areas.htm#:~:text=elevation%20mixed%20conifer.-,The%20climate%20is%20characterized%20by%20cold%2C%20snowy%20winters%20and%20warm,1778%20mm%20(70%20inches).][Oregon State University]].

[fn:PROV304] Precipitation and temperature data from [[https://www.hydroshare.org/resource/10664457c48342fa8b1e046ea740cd9c/][Hydroshare]], from 2008-2018. Data is taken hourly, so it was summed and averaged across years. For temperature, TACTUAL was used in the average.

** Process
*** MAT
Gathered mainly from [[https://www.ncei.noaa.gov/maps/annual/][NCEI at NOAA]].
- Turn on the "Annual Normals (2006-2020)" map layer, and disable the "Global Summary of the Year" layer.
- Put coords into floating search box, and find a station near enough to the site to be relevant.
- Click the wrench on "Annual Normals (2006-2020)", and use the rectangle tool to make a box around the station, just enough to select it.
- Select the station in the menu that appears on the left side of the page, and add to cart.
- In the new tab, click "Show List" under the "Data Types" text field.
- Type, filter, and select both "Annual average temperature mean" and "Annual precipitation totals"
- In the downloaded .csv, precip is labeled as ANN-PRCP-NORMAL, and temperature is labeled as ANN-TAVG-NORMAL.
*** MAP
Gathered mainly from [[https://www.ncei.noaa.gov/maps/annual/][NCEI at NOAA]].
- Turn on the "Annual Normals (2006-2020)" map layer, and disable the "Global Summary of the Year" layer.
- Put coords into floating search box, and find a station near enough to the site to be relevant.
- Click the wrench on "Annual Normals (2006-2020)", and use the rectangle tool to make a box around the station, just enough to select it.
- Select the station in the menu that appears on the left side of the page, and add to cart.
- In the new tab, click "Show List" under the "Data Types" text field.
- Type, filter, and select both "Annual average temperature mean" and "Annual precipitation totals"
- In the downloaded .csv, precip is labeled as ANN-PRCP-NORMAL, and temperature is labeled as ANN-TAVG-NORMAL.
*** NPP
NPP data is gathered from [[https://appeears.earthdatacloud.nasa.gov/][AppEEARS]].
- Navigate to Extract > Point, and make an account if you haven't.
- Start a new request.
- Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like /ID, Category, Lat, Long/.
  - You can alternatively upload a .csv with the same formatting, useful for large pulls.
- Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021.
- Scroll down to select layers to include in the sample.
- NPP is the first result. Make sure the data is yearly, not 8-day.
- Add other products if you wish, and submit the request.
- Depending on the size of the data requested, it can take up to a couple hours to process.
*** PET
PET data is gathered from [[https://appeears.earthdatacloud.nasa.gov/][AppEEARS]].
- Navigate to Extract > Point, and make an account if you haven't.
- Start a new request.
- Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like /ID, Category, Lat, Long/.
  - You can alternatively upload a .csv with the same formatting, useful for large pulls.
- Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021.
- Scroll down to select layers to include in the sample.
- Search for "Evapo yearly" select the first option.
- PET is labeled "PET", and AET is labeled "ET".
- Depending on the size of the data requested, it can take up to a couple hours to process.
*** AET, ET
AET data is gathered from [[https://appeears.earthdatacloud.nasa.gov/][AppEEARS]].
- Navigate to Extract > Point, and make an account if you haven't.
- Start a new request.
- Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like /ID, Category, Lat, Long/.
  - You can alternatively upload a .csv with the same formatting, useful for large pulls.
- Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021.
- Scroll down to select layers to include in the sample.
- Search for "Evapo yearly" select the first option.
- PET is labeled "PET", and AET is labeled "ET".
- Depending on the size of the data requested, it can take up to a couple hours to process.
*** DI
- DI and EP are calculated with PET and MAP products.
- PET / MAP
*** EP
- EP and DI are calculated with PET and MAP products.
- 1 - (PET / MAP)
*** GPP
GPP data is gathered from [[https://appeears.earthdatacloud.nasa.gov/][AppEEARS]].
- Navigate to Extract > Point, and make an account if you haven't.
- Start a new request.
- Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like /ID, Category, Lat, Long/.
  - You can alternatively upload a .csv with the same formatting, useful for large pulls.
- Set the dates. For this project, I was pulling from Jan 1, 2006 - Dec 31, 2021.
- Scroll down to select layers to include in the sample.
- GPP is only available in 8-day, which creates an extremely obnoxious problem - I solved this problem with an R script

- If you need to calculate yearly GPP for many different sites, the first script is intended for that purpose.
- If you only need to calculate yearly GPP for one single site, then scroll down for instructions.

** Initial .csv setup
- Before you begin, we will need to edit the excel file that AppEEARS gives us.
  - Keep only the needed columns: ID, Category, Latitude, Longitude, Date and GPP - Note that the actual GPP column is labeled something like "MOD17A2HGF_061_Gpp_500m"
    - There are many extra columns that you will need to delete.
    - Rename the GPP column to "GPP"
- Create a new column called "Year". The goal is to have this column show the year in YYYY format for every sample.
  - In the first cell (Should be E2 or F2), enter "=YEAR(D2)", where D2 refers to your date column. Change the cell type to "General" - you should see a year in YYYY format.
  - Extend this formula down to fill in the whole Year column.
  - Copy the whole column, and then Edit > Paste Special..., and select Values. This replaces the formula dependent cells with ones that show the year in plain text.
- The list of columns should now be ID, Category, Latitude, Longitude, Date, Year, GPP.
- In the script, "GPP all sites.csv" refers to the downloaded .csv - you will need to either rename your file or change this to change the call in the file to point to the correct location.

#+begin_src R
  library(dplyr)


gpp_data <- read.csv("GPP all sites.csv")

gpp_data <- gpp_data %>% filter(Year != 2005)

yearly_gpp <- gpp_data %>%
  group_by(ID, Category, Year) %>%
  summarize(total_GPP = sum(GPP, na.rm = TRUE), .groups = "drop")

average_gpp <- yearly_gpp %>%
  group_by(ID, Category) %>%
  summarize(average_GPP = mean(total_GPP, na.rm = TRUE), .groups = "drop")

write.csv(average_gpp, "average gpp.csv", row.names = FALSE)
#+end_src

#+RESULTS:

* DONE Mapping DI and EP with rgee :rgee:maps:
CLOSED: [2024-08-15 Thu 12:39]
:PROPERTIES:
:EXPORT_FILE_NAME: Mapping-DI-and-EP-with-rgee
:END:
[[/images/rgee_global.png]]
Note: I have a sneaking suspicion that trying this in Earth Engine proper using JS will significantly improve the results. The same goal attempted in rgee will remain available below, and a hopefully better JS version will appear above this in the coming days.

Note 2: JS version had the same issues and created more problems. Nevermind!
** Rgee version
*** Introduction
Goal: create global maps showing Dryness Index and Evaporative Index in both 2012 and 2019, using rgee.

This was pretty tricky to get working. The primary challenge was visualizing the data in a way that was meaningful, and preventing extreme values from obfuscating the scale.

**** Scale values / min and max
A major pain to get right. The values in the script below /are still not correct/ and the product generated *should not* be used for any purpose other than general visualization. Google Earth Engine documentation [[https://developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_TERRACLIMATE#bands][provides estimated min and max values and scale]], but using those results in seemingly useless visualizations. After trials, I found that the best visualization came from using max values of 4 for DI layers, and 2 for EI layers. Additionally, make sure to multiple all bands by 0.1 to account for scale.

**** Color palette
Another pinch point. At first, the map being dominated by extreme values seems like an issue that could be easily solved by using a more expansive color palette. In practice, this doesn't work. Going from only three colors to over twenty just creates more range in the areas of the map where range actually exists, instead of creating it in the areas that are solidly either the min or the max.
**** Data statistics
Interesting findings here that mostly reveal my own incompetence. Doing some light sniffing on the visualized values gives some very bizarre results: for both bands, the 50th percentile is 0. For EI, the 95th percentile is 0.662 and the 99th is 0.759. Similar values are present among both years and both DI and EI.
*** Script
#+begin_src R

# Load required libraries
library(rgee)
library(ggplot2)

# Initialize rgee: see docs.mor-gan.com/posts/setting-up-rgee/#initializing
ee_check()
ee_install_upgrade()
ee$Authenticate(auth_mode='localhost')
ee$Initialize(project='ee-pugbugdude')

# Define the years of interest
years <- c(2012, 2019)

# Function to load datasets for different years - continued with snippet below.
load_dataset <- function(year) {
  ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE")$
    filter(ee$Filter$calendarRange(year, year, "year"))$
    mean()
}

# Loads the dataset above for both defined years.
dataset_2012 <- load_dataset(2012)
dataset_2019 <- load_dataset(2019)

# Function to select bands and scale properly
# see developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_TERRACLIMATE#bands
# for scaling info.
get_scaled_bands <- function(dataset) {
  list(
    pet = dataset$select('pet')$multiply(0.1),
    aet = dataset$select('aet')$multiply(0.1),
    pr = dataset$select('pr')
  )
}

# Sets the bands for both years
bands_2012 <- get_scaled_bands(dataset_2012)
bands_2019 <- get_scaled_bands(dataset_2019)

# Calculate indices
# DI (Dryness Index) = PET / PR
# EI (Evaporative Index) = AET / PR
calculate_indices <- function(bands) {
  list(
    dryness_index = bands$pet$divide(bands$pr)$rename("Dryness_Index"),
    evap_index = bands$aet$divide(bands$pr)$rename("Evaporative_Index")
  )
}

# Calculates indices for both years
indices_2012 <- calculate_indices(bands_2012)
indices_2019 <- calculate_indices(bands_2019)

# Sets the palette to use for mapping.
index_palette <- c("blue", "cyan", "green", "yellow", "orange", "red", "darkred")

# Function to put layers on the map for both years and bands
# Uses variables set above
# Why: It's easier to be able to edit the palette, min, and max values
#  for all layers at once, rather than having to keep track of several different lines.
visualize_layer <- function(image, title, min, max) {
  Map$addLayer(
    image,
    list(min = min, max = max, palette = index_palette),
    title
  )
}

# Set min and max values for visualization.
# IMPORTANT: These are very, very finicky to figure out. The min and max listed at
# developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_TERRACLIMATE#bands
# will result in a wonky, poorly visualized map.
# The numbers used below are a best attempt effort that generates a product to be used purely for
# visualization, not a particularly accurate one. I strongly encourage you to adjust them to see how the map changes.
dryness_index_min <- 0
dryness_index_max <- 4

evap_index_min <- 0
evap_index_max <- 1.5

# Adds each of the layers to the map.
# In RStudio, the map should open automatically in the viewer tab.
# In other environments, the map should open in a browser tab.
visualize_layer(indices_2012$dryness_index, "DI 2012", dryness_index_min, dryness_index_max)
visualize_layer(indices_2012$evap_index, "EI 2012", evap_index_min, evap_index_max)

# Add layers for 2019
visualize_layer(indices_2019$dryness_index, "DI 2019", dryness_index_min, dryness_index_max)
visualize_layer(indices_2019$evap_index, "EI 2019", evap_index_min, evap_index_max)
#+end_src

* DONE Creating a .kml file from a Google Earth project
CLOSED: [2024-08-15 Thu 12:39]
:PROPERTIES:
:EXPORT_FILE_NAME: Creating-a-kml-from-a-project
:END:
** Introduction
"Keyhole Markup Language"

.kml files are useful for a number of reasons, namely storing pins, locations, polygons, images, and other GIS info. One of the easiest ways to make them is with Google Earth.

You can approach this in a couple of ways. Both the [[https://earth.google.com][Earth website]] and the [[https://www.google.com/earth/about/versions/][Google Earth Pro desktop app]] are usable.

** Google Earth Web
1. Open [[https://earth.google.com][Google Earth]] in a browser.
2. Open the left hand side bar. It's a little arrow in the middle of the left edge.
3. Click the "+ New" button, select "Local KML file", and click "Create".
4. You should see a new section, "Local KML files", and your new project, "Untitled".
   - You can rename the project by clicking on the kebab menu while hovering on it, and clicking "Rename".
5. Click on the project to select it.
6. To add a location to the project, navigate to it, and then click the "Save to project" button that appears in the card.
   - Alternatively, you can use the pin / placemark tool (first on the left in the toolbar) and it will be automatically added to the selected project.
   - You can rename the pin / placemark by either doing so when you initially place it, or by using the kebab menu in the project menu.
7. Once you are done adding to your project, you can export by clicking the kebab menu on it, and then selecting "Export as KML file".

** Google Earth Pro
1. Open [[https://www.google.com/earth/about/versions/][Google Earth Pro]].
2. Create a folder under Add > Folder. This is your project, so name it accordingly.
3. Create placemarks with the placemark tool.
   - They should be automatically placed into the new folder.
   - You can drag other objects inside of the folder to add them to the project.
4. Once you are done with the project, export it by right clicking on the folder and selecting "Save place as.."
   - There are two options to save: a .kml and .kmz.
   - If you don't know what to use, select .kml.
   - .kmz files are used to compress larger projects, typically ones that include images, but have some compatability issues.
* DONE Git basics
CLOSED: [2024-08-21 Wed 11:00]
:PROPERTIES:
:EXPORT_FILE_NAME: Git-basics
:END:

** Introduction to Git and GitHub
It's easiest to think of Git (and other forms of source control) like a time machine.
 * When you make changes to your project, it's easy to see what has changed.
 * You have a perfect history of everything that's ever happened in your project, and can always revert to any point in that history.
 * Git allows you to work with other people on the same project, while guaranteeing that you won't mess up each other's work.
 * Git allows you to send and receive files from your computer to a server, making it easy to put your projects online.

** Concepts
*Commits:* Think of a commit as taking a snapshot of your project. Every time you make a commit, you are saving a record of what your project looks like at that moment in time. This allows you to track changes over time and gives you a perfect history of your entire project.

*Repositories:* Where your project lives. Itâ€™s like a folder that stores all of your code and the entire history of your project. Repositories can live on your local machine or be hosted online via platforms like GitHub.

*Staging Area:* The staging area is like a holding ground where you prepare changes before making a commit. Think of it as packing a suitcase for a trip. When you lay everything out on your bed, thinking about what you want to bring with you, you can still move around, remove, and add items. The bed would be the staging area, and "committing" would be closing and locking your suitcase.
** How GitHub Works
GitHub stores your Git repository online. While Git is entirely local (everything is stored on your computer), GitHub hosts your repository online so that you can share it and collaborate with other people.
** Branches and Pull Requests
In Git, branches allow you to work on different versions of your project simultaneously. For example, if you are working on a major feature but you donâ€™t want to disrupt the rest of the project, a branch would allow you to create an alternate timeline where you can make changes without affecting the main project.

*Pull Requests* are used when working with other people to propose changes. If someone has code that they want to contribute to the project, they create a pull request to merge their work. This allows other team members to review the code before itâ€™s integrated.

** Glossary
Core Git Terms:
- Repository (Repo): A projectâ€™s directory or storage space where your projectâ€™s files and their revision history are stored.
- Commit: A snapshot of your project at a specific point in time. Each commit has a message and stores changes made to the code.
- Branch: A separate line of development within the same repository. You can think of branches as different versions of your project that diverge from the main version (typically called main or master).
- Clone: The process of creating a local copy of a repository from a remote server (such as GitHub).
- Fork: A personal copy of someone elseâ€™s repository, typically used to suggest changes or to start independent development.
- Pull Request (PR): A GitHub-specific feature. It allows developers to request that their code changes be merged into the main repository. It often involves code review before merging.
- Merge: The process of combining changes from different branches into one. It typically happens after a pull request is approved.
- Rebase: Similar to merging but instead of combining the changes from different branches, it rewrites the commit history by applying your changes on top of another branch. Useful for keeping a cleaner commit history.
- Remote: A version of your project hosted on a remote server (such as GitHub, GitLab, or Bitbucket). The remote is usually referred to as origin.
- Fetch: Retrieves the latest changes from the remote repository without applying them to your local repository.
- Pull: Retrieves the latest changes from the remote repository and applies them to your current branch.
- Push: Sends your committed changes to a remote repository (e.g., GitHub) so others can access them.
- HEAD: The current snapshot or commit that your working directory is based on. Itâ€™s typically the latest commit on the active branch.
- Staging Area: A place where you prepare changes before committing them. Think of it as a holding area where you decide what will go into your next commit.
- Index: Another name for the staging area.
- Checkout: The process of moving between different branches or commits in a repository. You are switching your working directory to match a particular branch or commit.
- Conflict: Occurs when Git is unable to automatically resolve differences between two commits (such as during a merge) because the same line of code was changed differently in both branches.
- Cherry-pick: Selectively applying changes from one commit in another branch without merging the entire branch.
* DONE Analyzing soil with a XRF
CLOSED: [2024-10-21 Mon 08:56]
:PROPERTIES:
:EXPORT_FILE_NAME: analyzing-soil-with-xrf
:END:
*Warning*: The XRF emits X-rays up to 50kV. Improper use can and will cause serious, long term harm to your health. Follow all safety protocols including those beyond this article.
** Introduction
This article assumes you already are in possession of pucks of finely ground soil.
** Procedure
1. *Prepare the XRF Analyzer*
   - Take the battery from the charger and insert it into the back of the XRF.
     - Note that a good amount of force is required to latch the battery into place.
   - Power on the XRF by holding the power button on the left of the front for about 3 seconds.
   - Wait for the system to boot.
   - Log into the device using the password.
   - The four directional buttons are used to select items on the interface.
   - The button to the right of the pad is the enter or confirm button, not a back button.
   - The center of the pad is not a button, which is incredibly unintuitive and confused me for an unbelievably long period of time.
   - From the main menu, select =System Check= to calibrate the scanner.

2. *Connect the XRF to a Computer*
   - Open the =NDTr= software from the start menu on the desktop. It should automatically connect to the XRF and mirror the deviceâ€™s screen on the computer.
     - If it doesn't, try some of the following.
     - The software should be the /only/ XRF-related piece of software open. If something else is open trying to communicate with the scanner, it won't work.
     - The scanner should be communicating on COM6. To ensure this is the case or to change it:
       - Maximize the window with the window decoration controls (e.g. _ â–¡ â˜’)
       - Click the now visible settings button.
       - Change the COM port to 6.
       - If it still won't work, ensure that the XRF is actually communicating on COM6.
         - Open Device Manager (search in start menu), and under "Universal Serial Bus", look for the scanner. Note the COM port.

3. *Prepare and Name the Samples*
   - Slide the latch on the XRF stand to the right and open the lid.
   - Place your sample puck on the XRF with the film side facing down.
   - Close the lid and lock it by sliding the latch back to the right.
   - Navigate to the =Sample Type= menu and select =Soils and Minerals=, then choose =Soils=.
   - Navigate to =Data Entry=, and click the glyph of the keyboard to enter the sample's name.
     - Note that you can use the computer's keyboard to type.

4. *Perform the Scan*
   - Ensure that the sample is centered on the sensor and that the lid is locked, then press and hold the trigger. The XRF will scan as long as you are holding the trigger, up to 10 seconds.
     - Ensure you hold the trigger for the same amount of time for all samples in a batch.
     - The longer the scan, the more accurate the results are, although scanning for more than 5 seconds is essentially redundant.
   - After the scan completes, open the lid and remove the sample, placing it on the lab bench film-side up.
     - Note: placing the sample film side down can easily destroy the puck.
   - Press the return key on the computer keyboard.
   - Enter a new sample name, and continue with the next sample.

5. *Download the Data from the XRF*
   - Once all samples have been scanned, click the =Disconnect= button on the computer and close the =NDTr= software.
   - Open the =NDT= software. The XRF should be connected to COM6.
   - Click =Test= to verify the connection. If successful, click =Query Readings= to retrieve the data from the XRF.
   - Scroll to the bottom of the readings list, select the samples you need, name the file, and click =Download= to save the data.
   - .ndt files can be opened in Excel or your text editor of choice.
* DONE Creating animations of soil cores out of CT scans
CLOSED: [2024-11-20 Wed 13:53]
:PROPERTIES:
:EXPORT_FILE_NAME:  creating-animations-of-soil-cores
:END:
** Introduction
Goal: To create animations of soil cores spinning from .vol files obtained from the Pacific Northwest National Laboratory.

We're getting our files from the Environmental Molecular Sciences Laboratory at the Pacific Northwest National Laboratory, who have scanned the soil cores with a Nikon XTH CT scanner.
** Requirements
- .vol files from a CT scanner
- At least 16gb of memory
  - [[https://downloadmoreram.com/][Ideally more]]. Both Fiji and Dragonfly attempt to load the entire file into memory; the downloaded .vol is almost 40gb.
- [[https://dragonfly.comet.tech/][Dragonfly from Comet Software]]. You'll need a license: [[https://www.theobjects.com/dragonfly/get-trial-version-request-comet.php][30 day free trials]] are easily accessible, and [[https://dragonfly.comet.tech/en/non-commercial-licensing][non commercial licenses are available]].
- [[https://fiji.sc/][Fiji]] or ImageJ, but use Fiji.
- A windows or Linux machine to run Dragonfly on; everything but that can be done on Mac
** TL;DR
- Download .vol files from [[https://sc-data.emsl.pnnl.gov/#state=32f73ab7-1755-4bad-8f02-a5640adf3a1a&session_state=0f3eb580-fa1b-48b2-aed4-6eefcad788f9&code=6f48e754-f383-442b-884b-f7222be36fbe.0f3eb580-fa1b-48b2-aed4-6eefcad788f9.21cf84f6-6ada-4d20-8b12-72f0a3e0bce3][EMSL Data portal]]
- Import the files into Fiji as raw data, 2000x2000x2000
  - Convert to 8-bit, save as .tiff
- Open the .tiff in Dragonfly, crop to slices 250-1800
  - Make a cylindrical mask to crop the garbage off the core
  - Use movie maker to make a rotating movie, export to .avi
- Use ffmpeg or similar to convert to mp4
- Use kdenlive or similar to crop to square
- Use Gifski to convert to reasonably sized gif

** Getting .vol files from EMSL data portal
*** Selecting cores
To start, we need to get the CT scan files from EMSL, provided as .vol files.
- Navigate to the [[https://sc-data.emsl.pnnl.gov/#state=32f73ab7-1755-4bad-8f02-a5640adf3a1a&session_state=0f3eb580-fa1b-48b2-aed4-6eefcad788f9&code=6f48e754-f383-442b-884b-f7222be36fbe.0f3eb580-fa1b-48b2-aed4-6eefcad788f9.21cf84f6-6ada-4d20-8b12-72f0a3e0bce3][EMSL data portal]], and login.
- On the left hand side of the screen, open the =Project= drawer and scroll down to the =Principle Investigator= field.
- Enter the first few characters of a name, and then check the cooresponding box.
- The main panel should update with the relevant project.
- Scroll down to the =Select Datasets= button, and click it.

You should now see a list of the datasets associated with that project. In this example, we're looking for individually numbered soil cores, but you will note that none of the data are labeled.

If you have a specific core number in mind, the only way to locate it is by looking inside of every single dataset by clicking the =DOI= button next to the =Upload ID=. You can then see the individual file names, which include the soil core number. If you decide to embark on a search to find a soil core, I recommend sorting by =Instrument= to only see XCT data, and then sort by file size. You are looking for datasets that are 29.8GB. Only view 10 datasets per page, as when you exit the DOI file viewer the entire webpage snaps to the top; it's easier to keep track of where you are when there are only 10 items.

Once you find the core you want, note the =Upload ID=. To search for an ID you already know, set Items per page to All, and use cmd + f.

Some known core ID's:
| Core # |  Bottom |     Top |
|      1 | 3132984 |         |
|      2 | 3134562 |         |
|      5 | 3135086 |         |
|      6 | 3135290 |         |
|      7 | 3049610 |         |
|     10 | 3133330 |         |
|     11 | 3051409 | 3051495 |
|     15 | 3010819 | 3010713 |
|     16 | 3011663 | 3013268 |
|     20 | 3010658 | 3010660 |

Some notes:
- Each core is 30cm tall, and the bottom 10cm and top 10cm were scanned.
- Each core is 7.62cm in diameter.
- 2000 slices per scan, meaning that each slice is 50Âµm (0.05mm) thick.
- If a core (including 1 & 6 listed above) is difficult to use or is seemingly empty, it's most likely because the soil profile wasn't tall enough for a full sample to be taken.

*** Downloading cores
Add each dataset to your cart by checking the box next to it. To download the cores, you will need to set up and use Globus.

Once EMSL prepares the files, you will see a link to go to the created guest collection. Open it, and navigate to your endpoint (computer) on the pane without the .tar in it. Go to the folder where you want the files to be downloaded to. Once there, select the tar on the other pane, hit =Transfer or Sync to...= in the middle, and then click start above the pane.

Globus will start transferring the file. You should get an email when its done. For reference, a 96GB transfer took a little over three and a half hours.
** Initial .vol work in Fiji
Unzip the tarball, and navigate through the mess of folders inside to get to the .vol files (each should be around 30GB). I recommend moving the .vols into their own folder, separate from the tarball's filesystem, because it's obnoxious to have to go 30 directories deep to get to them.

Notes:
- Each .vol has a corresponding .vgi that contains metadata about the .vol. Open it in a text editor if you want to know more.
- There are a number of other derived products in the tar, namely still images of the core and csv files with data (notably porosity).

Each .vol contains 2000 images, each of which is 2000x2000 pixels, totalling *8 billion voxels*, each of which is represented as a 32-bit floating-point number and saved in an uncompressed file. This makes the raw files wildly impractical to work with, hence the use of Fiji. The goal is to convert each file to 8-bit and save it as a .tiff, both of which should drastically reduce the size while losing no useable data.

Open Fiji, and use =File > Import > Raw...= to open the .vol.
- Image type: 32-bit Real
- Width: 2000
- Height: 2000
- Offset: 0
- Number of images: 2000
- Gap: 0

Check =Little-endian byte order= and =Use virtual stack=. Virtual stacks load the images without fully committing them to memory, making it possible to view datasets that are larger in size than the amount of memory you have. *If you don't have at least 40GB of memory and don't use virtual stacks, Fiji will crash your system attempting to load the file.*

Fiji will open the file, and you should be able to scroll through the slices of the core, or use the scroll bar at the bottom of the window containing the core.

To convert the file to 8-bit, use =Image > Type > 8-bit=. This will take time: you should be able to see Fiji converting images by the hundreds on the main toolbar.

You should now have an updated view of the core; notice the reduced file size displayed in the window title. To save as a .tiff, use =File > Save as > Tiff...=


** Working in Dragonfly
*** Loading & masking
In Dragonfly, open the newly created .tiff file with =File > Import Image Files...=. Click the =Add...= button, then select the file. Click =Next= in the bottom right.

The fields on this screen should be correct. Ensure that the =Total size= (on right, under Information) is less than the amount of memory you have.

Click =Crop Image...= and preview the image of the soil core. If the core doesn't take up most of the frame, crop it by dragging the green dotted edges or corners inward.

In the =Crop Image...= window, crop the image to slices 250-1800. Under the =Cropping= slider, enter 250 in the first field and 1800 in the second. Click OK.

Click =Finish=. After loading, you should see four views of the core: a 3D render and three orthogonal views. You can maximize a pane by double clicking, and you can move the 3D view by clicking and dragging in its pane. Double click again to return to all four views.

Notice the "fuzziness" or garbage data visible in the 3D view (most visible looking top down, around the edges). To remove this data, we need to create a cylindrical mask.

At the top of the 3D view, there is a row of buttons under the Shapes bar. Click the cylinder button, the third from the left - note the capsule button right next to the cylinder button.

You should see a wireframe cylinder insdie of the soil core. Using one of the side orthogonal views, drag the green lines outward, and stop when you hit the garbage data.

You should see the cylinder on the other views increasing and get a sense of what you're doing. Everything outside the cylinder will be excluded.

On the right hand side of the screen, you should see a list of the objects loaded: the core and the cylinder. Click on the cylinder, and look under =Shape properties=, =Visual effects=, =Visuals=. Check the box next to the core. Check =Outside=, then under 3D effects, =Clip=. You should see the 3D view update to exclude anything outside the cylinder.

*** Animating
Right click the 3D view and select =Show Movie Maker=. Double click the 3D view pane to maximize it. You'll need to position the 3D view to be what you want the video to look like: I position the core straight on, with the camera slightly raised above it at an angle so the top is visible.

Click and drag to manipulate the core, and click and hold the middle mouse button and move your cursor up and down to zoom in and out. To physically move the core in the 3D space, press x on your keyboard and click and drag. Make sure to press escape when you are done moving it to return to the default track tool.

Once you've positioned the core, look at the timeline near the bottom of the screen. At the 00:00 mark, you should see a square with a picture of the core in it. Right click it, and select =Update key frame=.

To actually rotate the core, click the =Rotate= button above the timeline. Choose one of the two right-most options (I use clockwise), and select =Rotate around the object's axis=. A second image, or keyframe, should appear on the timeline. Drag this second keyframe out to around the 20 second mark, or however long you want the video to be.

The original keyframe is where the animation will start, and the ending keyframe is exactly the same except that the core has been rotated 360 degrees. Dragonfly interpolates the motion in between the keyframes, so by dragging the 2nd keyframe further out along the timeline you are causing the core to spin slower.

You can drag the green bar marker along the timeline to preview the animation, or click the play symbol above the timeline. Note that the animation likely will not play at full speed, as it's rendering in real time.

To change the color of the background to a solid white, click the =Scene's Views Properties= bar in the left list of toolbars. Near-ish the top is a button next to =Background color=. In the window, you'll want to select =Uniform= under mode, and then click the button next to =Color 1= in the Color section on the right. In the color picker, drag the right mode slider up from black to white, and click OK, then OK. You should see the updated background.

To export the animation, click the =Export animation= symbol above the timeline, immediately next to the start / beginning symbol. Set the FPS to 60, the Dimensions preset to 1920x1080, and the bitrate to High. Click =Save as Video File=. Once you've given a name and location for the file, Dragonfly will render and export the animation as an .avi file.

** Working with .avi video files.
Once you have the exported .avi files, the goal is now to convert them into a more common, useable format. If you want to create .gif files out of the animations, a few different steps are needed. In general, you need to:
- Convert the .avi into a more useable format (.mp4)
- Crop the new .mp4 into the a square aspect ratio. This looks nice, and crops out the small cube axis visualizer in the bottom right of the frame.
- Convert the .mp4 into a .gif.

These steps can be completed in a little over 3 trillion different ways. In this guide, I'll use ffmpeg for converting files, kdenlive for cropping, and Gifski for making the .gifs, but it's practically much easier to use software like Adobe Premiere Pro or Final Cut Pro ([[https://www.apple.com/final-cut-pro/trial/][free 90 day trial!]]) if you have access to them.

You can get ffmpeg from [[https://www.ffmpeg.org/download.html][their website]], or install it (on mac) with homebrew by running ~brew install ffmpeg~ in a terminal. Kdenlive is [[https://kdenlive.org/en/download/][available online]]. Gifski is available on the mac app store ([[https://github.com/sindresorhus/Gifski][link on GitHub]])

I would recommend working in a folder where all of your video files are, which prevents you from needing to type out full paths for the following commands.

*** Converting .avi to .mp4 with ffmpeg
To convert an .avi into a .gif:
#+begin_src
ffmpeg -i input.avi -vcodec libx264 -crf 23 -preset medium output.mp4
#+end_src
where ~input.avi~ is the .avi file and ~output.mp4~ is the desired output file.

With the new .mp4, you can move on to cropping.

*** Cropping with Kdenlive
In kdenlive, add the clip to the timeline with =Project > Add Clip or Folder...=, then select the .mp4. If you get prompted to =Switch to clip profile HD 1080p 60 fps=, click cancel. Instead, we want to change the project to be a square aspect ratio.

Navigate to =Project > Project Settings...=, then under the list of folders of profiles, scroll down to =Custom=, open the folder, and select =Square 1080p 60 fps=. Click OK, then confirm.

In the top left panel, you should see the .mp4 under the =Sequences= folder. Drag it to the V1 timeline, highlighted in blue. Be sure to drag it to the far left, so that it starts at 0:00.

The vertical white line is your *Playhead*, which represents where in the video the preview monitor is showing. Drag the top of the playhead on the timeline to skim through the video.

Note that there are two soil cores on your screen: The monitor on the left is displaying the source clip, while the one on the right is displaying your entire project. Once we apply effects (cropping the video), you'll be using the monitor on the right for reference.

To do this, go to the =Effects= tab, underneath the far top left panel, about halfway down your screen. Use the search field at the top to search for =Transform=, and double click it. You should notice that the effect appears on the list of effects to the right of the timeline.

In that panel, change the =Size= variable to 179%. The core should now fill the frame. Use your spacebar as a play/pause button and you should see the soil core rotating.

At this point, the video should be complete and ready to export. To do this, go to =Project > Render...=, and select the =MP4-H264/AAC= preset. Click the small file button next to the =Output file= field to select where you want to save the file. Once you are done, click the =Render to File= button at the bottom left of the window to start rendering.

*** Converting a .mp4 file to a .gif with Gifski
Open Gifski, and either drag the cropped .mp4 into the window or select it with the file picker. The app is incredibly simple to use compared to the stuff that was happening up there. There is a quality slider, and an estimated file size. I would set the fps to 50 to make it as smooth as possible.

Smash =Convert= once you are happy with the estimated size, and enjoy.


Wooo!!!!
# watch https://newbeelearn.com/tools/videoeditor/ for alleged export settings. makes life easier if added
* DONE Using the EGM-4 & open-egm4 software
CLOSED: [2026-02-01 Sun 15:25]
:PROPERTIES:
:EXPORT_FILE_NAME:  using-the-egm-4
:EXPORT_HUGO_PAIRED_SHORTCODES: alert2
:END:

#+TITLE: Using the PP Systems EGM-4 Environmental Gas Monitor
#+AUTHOR: Morgan Salisbury
#+DATE: 2026-01-30
#+attr_shortcode: Warning
#+begin_alert2
*Backup your data regularly.*  The EGM-4's internal memory is limited to 9999 records and 99 plots. Failing to dump data regularly will result in data loss when this buffer fills. When memory is full, the oldest records are overwritten.
#+end_alert2

#+attr_shortcode: Warning
#+begin_alert2
*You are responsible for your data.* Significant care has been taken to ensure data safety. However, by using the open-egm4 software, you accept the risk of data loss. Open-egm4 can not send commands to the EGM-4 itself, and therefore cannot damage it internally.
#+end_alert2
#+attr_shortcode: Caution
#+begin_alert2
*Don't get water in the gas lines.* If you do, it might enter the IRGA itself and damage it. It's like $15,000 to replace.
#+end_alert2

** Introduction
The PP Systems EGM-4 (EGM) is a portable infrared gas analyzer (IRGA) designed for measuring soil COâ‚‚ efflux. The device connects to various chamber types and soil probes, and stores measurements in its internal memory.

The open-egm4 software is a terminal interface designed to make data collection from the EGM reliable and easy. Unlike the legacy (read: outdated, buggy and frustrating) Windows software from PP Systems, this runs on macOS, Linux, and modern Windows systems.

This guide covers operation of the EGM itself, the SRC-1 chamber, how to use them alongside the open-egm4 software, common field scenarios and troubleshooting everything involved.

** Installing open-egm4

*What is open-egm4?*
- A terminal-based (text interface) application that communicates with the EGM
- Provides real-time COâ‚‚ visualization, data logging, and exporting of said data to a csv
- Works on any modern operating system
- Can run over SSH for remote field work (if anyone thinks of a genuine use case for this [[mailto:egm4@mor-gan.com][please tell me]])

*What is a Terminal?*
A terminal (also called "command line" or "shell") is a text-based interface for your computer. Think of it as typing commands directly to your computer instead of clicking on icons. Using a computer through the terminal (or, pedantically, /it's/ terminal) typically gives you much greater control and choice over its operation. In this case, open-egm4 was developed as a TUI (/terminal user interface/: an app that runs inside of the terminal) because it allows the app to be significantly smaller, more portable, and more lightweight to run on underpowered computers.

For more information on my debatable decision to develop the app for the terminal, see [[Why a Terminal Interface?][the appendix]].

*System Requirements:*
- macOS 10.14+, Windows 10+, or any modern Linux
- Python 3.8+ (the installer handles this automatically)
- USB serial port or USB-to-serial adapter
   - /Note/ If you are buying a USB-serial adapter, make sure to get one that uses a FTDI chipset. Cheap adapters often use "Prolific" chips which have notoriously bad drivers. FTDI chips are easier and require zero thought to use.
- Internet connection (for installation only)

*** One-Line Installation

This is the easiest method. A script handles everything: installing Python dependencies, downloading the software, and setting up shortcuts so you can run ~open-egm4~ from anywhere.

**** Step 1: Open Your Terminal

*macOS:*
1. Press ~Cmd + Space~ to open Spotlight search.
2. Type "Terminal"
3. Press Enter
4. A window with white or black background appearsâ€”this is your terminal.

*Windows:*
1. Click the Start Menu (Windows logo)
2. Type "cmd" or "PowerShell"
3. Press Enter
4. A window appears with textâ€”this is your command prompt (command prompt is exclusive to Windows; it is /a/ terminal. It has also been around since the 80s: PowerShell is Microsoft's attempt at an updated terminal for Windows.)

*Linux:*
You already know how to open a terminal.

**** Step 2: Copy and Paste the Installation Command

#+attr_shortcode: Caution
#+begin_alert2
*With great power...* Entering commands into a terminal gives you much more control over your computer than most users are used to. While this power is beneficial for knowledgeable users, it also makes it easy to make potentially irreversible mistakes.
#+end_alert2

#+attr_shortcode: Warning
#+begin_alert2
*...comes great responsibility.* You should never copy and paste commands into your terminal from sources you do not trust. A malicious command could delete files, install malware, or send your data to an attacker. While *I* wrote this script, you are ultimately trusting /me/ not to do something harmful. You can (and really should) view the install script source before running it.
#+end_alert2

In your terminal window, copy and paste this line as written:

#+BEGIN_SRC bash
curl -sSL https://raw.githubusercontent.com/mmorgans/open-egm4/main/install.sh | bash
#+END_SRC

*How to Paste in Terminal:*
- *macOS*: Press ~Cmd + V~ (normal paste works)
- *Windows (cmd)*: Right-click in the window, select "Paste"
- *Windows (PowerShell)*: Right-click to paste, OR ~Ctrl + Shift + V~
- *Linux*: ~Ctrl + Shift + V~ (not ~Ctrl + V~!)

Press ~Enter~ to run the command.

**** Step 3: What You'll See During Installation

After pressing Enter, text will start scrolling down the screen. You'll see messages like:

#+BEGIN_EXAMPLE
[INFO] Checking prerequisites...
[INFO] Installing fresh to /Users/hello/.open-egm4...
[INFO] Creating virtual environment...
[INFO] Fetching latest version and installing dependencies...
#+END_EXAMPLE

The installation takes 1-3 minutes depending on your internet speed. When you see "Installation Complete", it's done.

*Troubleshooting*:
- On Linux, you might need to add your user to the ~dialout~ group to access the serial port. You can do this with the command ~sudo usermod -a -G dialout $USER~
- If you see "curl: command not found" on Windows, try using PowerShell instead of cmd
- If you see "Python not found", the installer will attempt to install it automatically
- If installation fails, try the manual installation below. If it still doesn't work, [[mailto:egm4@mor-gan.com][shoot me an email]] and I'll try to help.

*** Pip Installation

If you're comfortable with Python environments:

#+BEGIN_SRC bash
# Install via pipx (recommended for isolation)
pipx install git+https://github.com/mmorgans/open-egm4

# OR install in your active virtual environment
pip install git+https://github.com/mmorgans/open-egm4
#+END_SRC

If you want to edit the code of open-egm4, there are more instructions on [[https://github.com/mmorgans/open-egm4][the repository page]].

*** Initial Connection to the EGM-4

Once software is installed, connect the EGM to a computer:

1. *Physical Connection:*
   - Connect the serial cable to the EGM's RS232 port
   - Connect the USB-to-serial adapter to your computer
   - Power on the EGM with the switch on the back

2. *Launch the Software:*
On your computer, in the terminal, run
#+BEGIN_SRC bash
open-egm4
#+END_SRC

1. *Select Serial Port:*
   - The software will list available serial ports (e.g., ~/dev/tty.usbserial~, ~COM3~)
   - It will also attempt to guess at which one the EGM is connected to and automatically connect to it
   - If it doesn't, select the port manually using the arrow keys, and hit Enter to confirm your choice. If you don't see your port listed, check the cable connection and hit ~r~ on your keyboard to refresh the list of ports.
   - On macOS, look for ports containing "usbserial" or "FTDI"
   - On Windows, look for "COM" ports (COM3, COM4, etc.)

2. *Verify Connection:*
   - The EGM screams out data over the serial connection, but it's incapable of receiving any data back. Therefore, you'll have no way of knowing if you're actually connected to the EGM unless you dump some data to your computer.
   - Details on how to collect data are [[Workflow 3: Dumping Stored Data from EGM-4 Memory][in the workflow section]], but for now you can verify that the software was installed correctly by dumping existing data from the EGM to your computer, assuming that there is pre-existing data on the EGM.
   - To send data from the EGM to a computer, press ~4DMP~ on the EGM, then ~2 DATA DUMP~, then press any key to begin the transfer.
   - If you see the data streaming in on your computer, celebrate. If you don't, then check out [[Troubleshooting & Maintenance][the troubleshooting section]].

3. *Press ~q~ to quit* (or ~Ctl + c~, which should quit most running terminal commands) when you're done exploring.

** EGM-4 hardware

*** Physical Interface & Controls

The EGM-4 is a portable, battery-powered COâ‚‚ analyzer. Key components:

*Front Panel:*
- *LCD Display*: 2Ã—16 character display
- 1-9 keypad, along with ~Y/R~ key (used for accepting and recording) and ~N~ key (used for denying and going back)
- ~8/X~ allows you to toggle between display screens while taking a measurement
- ~0/Z~ allows you to manually zero the EGM-4 during a measurement

*Top:*
- *Gas In Port*: Connect sample inlet tubing (1/8" ID)
- *Gas Out Port*: Exhaust port (1/8" ID) AND (counter-intuitively) should be used as an injection port for static syringe samples
- *I/O Connectors*: Two 15-pin D-sub connectors for sensors (notably the SRC-1)
- *RS232 Port*: 9-pin connector for data transfer to a computer

*Back:*
- *Power Switch*: Self explanatory
- *12V DC Charge Socket*: For charging the internal battery /and/ running the EGM off of mains power
- *Fuse*: 1A fuse
- *Soda Lime Cap*: Access to the COâ‚‚ scrubbing column for replacing it.

*** Power & Battery

The EGM-4 uses a 12V 2.0Ah sealed lead-acid battery. It should last around 4 hours of use at 20ÂºC. If the temperature is below 5ÂºC, the battery life drops 30-40%.

#+attr_shortcode: Note
#+begin_alert2
At low temperatures, you should hold the EGM inside your jacket, maintaining skin-to-skin contact. This will increase the battery life by a few minutes, and will psychologically bond you with the device.
#+end_alert2

*Charging:* The manual purports that the battery takes 12 hours to charge fully. /I/ think that's a made up number, and in my testing it's ready for action after around 2 hours. Your mileage may vary.

If you are planning on storing the EGM long term, charge the battery beforehand to avoid damaging it.

#+attr_shortcode: Warning
#+begin_alert2
The EGM's internal clock loses time when the battery dies. After replacing or fully recharging the battery, make sure the date/time settings are correct before taking measurements. This is critical for ensuring that your data is properly timestamped.
#+end_alert2


*Replacement:* To replace the battery, see [[Troubleshooting & Maintenance][the troubleshooting section]].

*** SRC-1 Soil Respiration Chamber

The SRC-1 is a soil respiration chamber that allows you to measure the rate of soil respiration by monitoring the rate of increase of COâ‚‚ concentration within a closed system: the chamber itself. See the [[*Workflow 1: Soil Respiration with SRC-1 Chamber][SRC-1 Workflow section.]]

** open-egm4 software

This section covers how to use the open-egm4 software, assuming you've already installed it. 

Launch the software by running ~open-egm4~ in your terminal.

*** Connection screen

When you launch the software, you'll see the connection screen, with a list of ports. 

Open-egm4 will attempt to detect which port the EGM-4 is connected to and automatically connect to it after 5 seconds. Use the arrow keys to cancel this countdown and select a port manually. 

To select a port manually, use the arrow keys to navigate the list of ports and press ~Enter~ to confirm your selection. If you don't see your port listed, check the cable connection and hit ~r~ on your keyboard to refresh the list of ports. If you accidentally select the wrong port, hit ~q~ to quit and try again.

- On macOS and Linux, the EGM-4 will likely appear as a port containing "usbserial" or "FTDI"
- On Windows, the EGM-4 will likely appear as a "COM" port (COM3, COM4, etc.)

Open-egm4 automatically saves data to its internal database. This allows you to restore from a previous session without having to re-dump data from the EGM. To do this, press ~s~ while on the connection screen. You'll see a list of saved sessions, and you can use the arrow keys to select one and press ~Enter~ to restore it. You do not need to have the EGM connected to the computer to restore a session. While the EGM is not connected, "Offline" will be displayed in the status panel.

*** Main interface

This is the main interface, where you'll spend most of your time. It consists of: 

*Left Panel - Graph:* This panel displays incoming data from the EGM, whether it be from a live measurement or previously generated data. The axes will automatically rescale to fit the data. The units will also change depending on how you are viewing the data, so be sure to check the legend to understand what you're looking at.

Directly below the graph are the available channels and graph controls. The available channels will change depending on what probe was connected when the the data was recorded. Press the number key associated with each channel to view that channel in the graph. 

Above the graph, you'll see information about what the graph is currently displaying, including the currently selected channel, the units of the y-axis, and the plot number. 

Press the ~<~ or ~>~ keys to cycle through different plots. This is useful to view measurements from a specific location (i.e. a plot in the field), and to filter out data you aren't interested in viewing.

Press ~i~ to toggle inspect mode on the graph. In this mode, a yellow ~x~ appears on the graph, and you can use the left and right arrow keys to move the cursor along the x-axis. The y-values for the currently selected channel at the cursor's position are displayed above the graph. Press ~i~ again to exit inspect mode.

*Right Panels - Status and Log:* These panels display the current status of the EGM and the log of recent events. The status panel shows the current COâ‚‚ concentration, along with derived statistics from that value. The log panel shows EGM system messages and app events.

*Footer:* The footer displays a list of all commands, along with their keyboard shortcuts.

**** Keyboard Commands

| Key     | Action                             | Description                                  |
|---------+------------------------------------+----------------------------------------------|
| ~q~       | Quit                               | Saves and exits as quickly as possible       |
| ~e~       | Export                             | Opens the export screen to save data as CSV  |
| ~c~       | Clear                              | Clears all chart data (with confirmation)    |
| ~p~       | Pause                              | Pauses/resumes the data stream               |
| ~n~       | Note                               | Add a timestamped note to the log            |
| ~b~       | Big Mode                           | Large COâ‚‚ display for visibility outdoors    |
| ~d~       | Theme                              | Toggle between dark and light themes         |
| ~i~       | Inspect                            | Toggleable mode to examine individual points |
| ~?~       | Help                               | Information about the app                    |
| ~1~ - ~9~   | Switch between data channels       |                                              |
| ~,~ / ~.~   | Cycle between different plots      |                                              |
| ~<~ / ~>~   | Same as above: plot selection      |                                              |
| ~â†~ / ~â†’~ | Move cursor (when in Inspect mode) |                                              |


**** Exporting data

Press ~e~ to open the export screen. This allows you to filter and export your data.

At the top of the export screen, you'll see the number of data currently selected to export. Initially, this will be all of the data currently in the app.

*Filtering data*
To export only a subset of that data, use the ~p~ and ~d~ keys to select only certain plots and dates, respectively.

To select specific plots to export, press ~p~ to open the plot selection screen. Use the arrow keys to navigate the list of plots and press ~Space~ to select or deselect a plot. Press ~p~ again to confirm and return to the export screen.

To select specific dates to export, press ~d~ to open the date selection screen. Use the arrow keys to navigate the list of dates and press ~Space~ to select or deselect a date. Press ~d~ again to confirm and return to the export screen.

You should see the number of data points to export update as you make your selections. Once you've selected the data you want to export, press ~e~ to export the data.

*Output*
.csv files should be saved to your Downloads directory. If this fails, the file will be saved in the same directory as open-egm4 was run in (likely your home directory). 

**** Pausing (~p~)

Press ~p~ to pause the data stream. While paused, the chart will stop updating with data, but you can still interact with the app. This is useful if you need to examine the chart without it updating with new data. Press ~p~ again to resume the data stream.

**** Adding notes (~n~)

Press ~n~ to add a timestamped note to the log. This will open a prompt where you can type a note. Press ~Enter~ to save the note, or ~Esc~ to cancel.

**** Clearing data (~c~)

Press ~c~ to clear all data from the current session. You will be asked to confirm before the data is cleared.

#+attr_shortcode: Note
#+begin_alert2
This does not clear data from the EGM's internal memory, only data that you have already dumped to the app. To clear data from the EGM's internal memory, see the initialize section.
#+end_alert2

*** Quitting (~q~)

Press ~q~ to quit the app. All data from your session are automatically saved (distinct from .csv files you may have exported), and you can restore it the next time you open the app by pressing ~s~ while on the connection screen.

#+attr_shortcode: Note
#+begin_alert2
Open-egm4 automatically saves data to an internal database. To restore from a previous session, see [[Connection screen][the connection screen section]].
#+end_alert2


** Workflows
*** Workflow 1: Soil Respiration with SRC-1 Chamber
:PROPERTIES:
:ID:       74928d06-d4ee-4910-b8a1-3a32f84d87fc
:END:

This is the most common application: measuring COâ‚‚ efflux from soil using the SRC-1 closed-chamber method.

*Equipment Needed:*
- EGM-4 with fully charged battery
- SRC-1 soil respiration chamber
- Soil collars*
- Optional: Laptop running open-egm4 for monitoring

*Soil Collars*: Install the soil collars well before you plan to measure (this should be planned prior to doing field work). A well-placed collar should be installed 3-5cm deep into the soil surface. Remove any aboveground vegetation inside the collar.

#+attr_shortcode: Note
#+begin_alert2
The above instructions depend almost /entirely/ on your situation. You might consider installing the soil collar weeks or months ahead of time. The depth of the collar needed to ensure a good measurement will depend on the soil type and the goals of your experiment.
#+end_alert2

*Field Procedure:*

1. *Connect SRC-1 to EGM-4:*
   - Connect the I/O cable of the SRC-1 to the EGM-4
   - Connect the gas tube labeled "R" to the gas in port of the EGM-4
   - Connect the unlabeled gas tube to the gas out port of the EGM-4

2. *Startup & Warmup (10-15 minutes):*
   - Power on EGM-4
   - Wait for warm-up message to complete: the EGM must reach an internal temperature of 55Â°C to be able to take readings

3. *Enter Measurement Mode:*
   - Press ~1~ (REC) from main menu
   - EGM-4 displays measurement settings
   - Default: DT=120 seconds (measurement duration), DC=50 ppm (max COâ‚‚ change)
   - Press ~N~ to go back and change settings, and ~Y~ to confirm settings

#+attr_shortcode: Note
#+begin_alert2
You should think carefully about the DT value that you set for a given measurement. If the DT value is too large the rate at which COâ‚‚ accumulates in the chamber will decline, and your estimate of the efflux rate will be less accurate. 
#+end_alert2

4. *Set Plot Number (if needed):*
   - Display shows "PLOT NO = X"
   - Press ~Y~ to keep current plot number
   - Or enter a new plot number (e.g., "01" for plot 1) and press ~Y~

#+attr_shortcode: Warning
#+begin_alert2
If you use a plot number that has already been used, the EGM will overwrite the previous measurement, causing irreversible data loss.
#+end_alert2

5. *Chamber Flush:*
   - This happens automatically. The display will show "CHAMBER FLUSHING - HOLD IN AIR"
   - Hold the chamber in the air for ~15 seconds at arms length

6. *Deployment:*
   - Display shows "PLACE ON SOIL - PRESS Y TO START"
   - Place the chamber on the soil collar, using blue tac to ensure a good seal
   - Press ~Y~ to start measurement

7. *Equilibration:*
   - Display shows "EQUILIBRATION - PLEASE WAIT"
   - System equilibrates for ~5 seconds
   - Then measurement begins automatically

8. *Measurement:*
   - Display shows:
     #+BEGIN_EXAMPLE
     C 420 H14.7 T22
     A02.11 Q0000 110
     #+END_EXAMPLE
   - ~C~: Current COâ‚‚ (ppm)
   - ~H~: Humidity (mb, if sensor connected)
   - ~T~: Soil temperature (Â°C, if sensor connected)
   - ~A~: Calculated flux rate (g COâ‚‚ mâ»Â² hrâ»Â¹)
   - ~Q~: PAR light level (if sensor connected)
   - ~110~: Elapsed time (seconds) â€” shows "END" when complete
   - After a measurement, you will be prompted to save the measurement with "RECORD Y/N"
   - Press ~Y~ to save the measurement
   - Press ~N~ to discard and retry

9. *Remove Chamber & Continue:*
    - Display shows "REMOVE FROM SOIL THEN PRESS Y KEY"
    - Lift chamber from soil collar
    - Press ~Y~ to prepare for next measurement

#+attr_shortcode: Caution
#+begin_alert2
The plot number will *not* auto-increment. You must manually enter the plot number for each measurement. Note that the EGM will happily overwrite the previous measurement if you don't change the plot number between measurements!
#+end_alert2

10. *Data Storage:*
If you had a laptop connected to the EGM while you were taking measurements, then you were able to view the incoming data in real-time and export it at will. If not, the data are stored in the EGM's internal memory. The EGM stores up to 999 records, and will start overwriting old records if full. See for [[Exporting data][instructions on how to export data from the EGM]].

*** Workflow 2: Static Sampling via Syringe Injection

Static sampling is used when you want to measure COâ‚‚ concentration of a discrete air sample without continuous flow. Common applications: measuring gas concentrations from sealed containers, soil headspace, or captured gas samples.

Instead of pumping air continuously through the EGM-4, you inject a small volume of sample directly into the measurement cell using a syringe. The internal pump is turned off to avoid diluting your sample.

*Equipment Needed:*
- EGM-4 with battery
- Luer-lock syringe (5-10 ml)
- Sample collection vial (if collecting from field, and perhaps if collecting in the lab)

*Setup Procedure:*

1. *Enable Static Sampling Mode:*
   - From Main Menu, press ~2~ (SET)
   - Press ~3~ (PMP) to access pump control
   - Current display shows "SAMPLE PUMP ON / Y/OK N/CHANGE"
   - Press ~N~ to change
   - Display now shows "STATIC SAMPLING / Y/OK N/CHANGE"
   - Press ~Y~ to confirm

2. *Prepare for Injection:*
   - Press ~1~ (REC) to enter measurement mode
   - EGM-4 now displays COâ‚‚ concentration
   - Display will show the current COâ‚‚ concentration

*Sampling Procedure:*

1. *Collect Sample:*
   - Draw sample into syringe, at least 5 ml is required for a stable reading.

2. *Inject Sample:*
   - Locate the Gas Out port on top of EGM-4
   - Inject sample into the Gas Out port
   - Watch COâ‚‚ reading on display

3. *Read Stabilized Value:*
   - The COâ‚‚ reading will change as your sample fills the cell
   - Wait 10-20 seconds for reading to stabilize
   - Reading is stable when it changes less than 1-2 ppm over 30 seconds
   - Press ~Y~ to record measurement

4. *Flush Between Samples:*
   - Inject ambient air several times to flush
   - Or wait for auto-zero cycle (warnings appear at 2 min and 1 min before zero)
   - During zero, pump turns on automatically to flush cell, then turns off

*Auto-Zero Warnings in Static Mode:*
The EGM-4 will still perform automatic zeros even with pump off. You'll see warnings:
- "AUTO ZERO IN 2 MINUTES"
- "AUTO ZERO IN 1 MINUTE"

When zero begins, the pump turns on for ~15 seconds, then turns off again. This ensures an accurate baseline.

#+attr_shortcode: Caution
#+begin_alert2
Don't forget to re-enable the pump when finished.
#+end_alert2

*** Workflow 3: Dumping Stored Data from EGM-4 Memory

To transfer stored records from the EGM-4 to your computer, do the following: 

1. Connect the EGM-4 to your computer using a serial cable and USB adapter
2. Power on the EGM-4 and open the open-egm4 app on your computer by typing ~open-egm4~ in the terminal
3. Press ~4DMP~ from the Main Menu on the EGM-4, then Press ~2 DATA DUMP~
4. Once the open-egm4 app is ready, press any key on the EGM-4 to start the transfer
5. View your data on the graph, and use the ~<~ and ~>~ keys to view a specific plot
6. Press ~e~ to open the export menu. Use the ~p~ and ~d~ keys to select the plot(s) and/or date(s) you want to export, then press ~e~ to export
7. The .csv will be saved to your Downloads directory

*Data Record Structure:*

Each record contains (in CSV format):
- M/R flag (M=real-time, R=stored record)
- Plot number (0-9999)
- Record number (1-9999)
- Date (day, month)
- Time (hour, minute)
- COâ‚‚ (ppm)
- Hâ‚‚O vapor (mb, if sensor present)
- RH/Temp sensor data
- Sensor inputs A-E (mV values)
- Atmospheric pressure (mb)
- Probe type (0-11)

** Troubleshooting & Maintenance

#+attr_shortcode: Warning
#+begin_alert2
Only open the unit if you feel comfortable with electronics. Static discharge can damage sensitive components. Ground yourself before poking around.
#+end_alert2

*** Replacing the Soda Lime COâ‚‚ Scrubber
The EGM needs to know what zero COâ‚‚ looks like to make accurate measurements, and uses the soda lime to figure that out. Gradually, the granules in the soda lime column become saturated with COâ‚‚ and can no longer absorb it, becoming pale in color as they do so. Replace when around 2/3 of the column have changed color.

To do this, unscrew the black cap on the back panel, pour out the old granules, and fill the column with fresh soda lime, leaving about an inch of space at the top. Replace the foam filter and cap. 

#+attr_shortcode: Warning
#+begin_alert2
Wash your hands after handling soda lime. It's caustic.
#+end_alert2

*** Replacing the Internal Battery
The internal battery will need to be replaced after a few years of use. To do this, unscrew the 

flip the egm on its back

4 screws

flip the egm back over, carefully so it doesn't fall out of the case

remove the outer cover

remove the two screws on the back cover, and, leaning the back cover away from the EGM, carefully remove it. 

fix this section

*** Replacing internal tubing

Over time, the internal gas tubing will become aged and leak air. You'll need to replace it with 1/8" tubing, being careful not to create kinks or bends in the tubing. If you need 90 degree bends, some are availabe at McMaster-Carr (item number 5463K42).

*** EGM-4 error codes

The EGM-4 displays numbered error codes when problems occur:

*Error 01: Zero Too Low*
- *Cause*: Soda lime exhausted, absorber column not seated, or valve failure
- *Solution*:
  1. Replace the soda lime.
  2. Ensure the soda lime cap is tight.

*Error 02: COâ‚‚ < 250 ppm*
- *Cause*: Either genuine low COâ‚‚ or same as Error 01
- *Solution*: If you're measuring ambient air (~400 ppm), this indicates same problems as Error 01

*Error 03: Analyzer Temperature < 50Â°C*
- *Cause*: Instrument too cold or thermostat failure
- *Solution*:
  1. Allow longer warm-up time, or move somewhere warmer.

*Error 04: Analyzer Temperature > 60Â°C*
- *Cause*: Instrument overheating or thermostat failure
- *Solution*:
  1. Turn off, allow to cool.
  2. Check for ventilation blockage.

*Error 05: RH > 90%*
- *Cause*: High humidity or water in sample line
- *Solution*: In humid conditions, this may be normal.

*Error 06: Battery Voltage Low*
- *Cause*: Battery voltage < 10.5V
- *Solution*: Recharge the battery. If problem persists, replace the battery.

*** Software Connection Issues

- *"command not found"*: Installation didn't complete. Try re-installing.
- *"No module named 'serial'"*: Missing dependencyâ€”reinstall with ~pip install pyserial~

*Can't connect to EGM-4:*
- Check the cables and make sure they're securely connected 
- Check EGM-4 is powered on
- Verify you selected the correct serial port
- Try a different serial port if multiple are available
- On Linux: check permissions (~ls -l /dev/ttyUSB0~ should show you have read access)
** Technical Appendix

*** A: Serial Protocol Specification

The EGM-4 communicates over RS-232 serial at 9600 baud, 8 data bits, no parity, 1 stop bit, and no flow control. This is a standard configuration supported by virtually all serial terminal software.

Each data record is exactly 61 characters long (1 letter followed by 60 digits), with no spaces or delimiters, terminated by a carriage return and line feed (~\r\n~). The manual refers to "60 digits" which excludes the initial M/R mode character. During live measurements, the EGM transmits one record per second. When dumping stored data, all records are sent consecutively.

Here's an example raw record:

~R000002180313170042900000000000000000000000000400000000096508~

The table below shows how to interpret parsed records. Both real-time measurements (~M~) and stored records (~R~) use the same format:

| M/R | Plot No. | Rec No | Day | Mo | Hr | Min | COâ‚‚ Ref | Hâ‚‚O Ref | RHT   | A    | B    | C    | D    | E    | F    | G  | H  | AP  | PT |
|-----+----------+--------+-----+----+----+-----+---------+---------+-------+------+------+------+------+------+------+----+----+-----+----|
| M   |        1 |      1 |  28 |  1 | 13 |  19 |     968 |       0 | 000.0 | 0000 | 0000 | 0000 | 0000 | 0000 | 0000 | 00 | 00 | 991 |  0 |
| R   |        1 |      2 |  28 |  1 | 13 |  21 |     930 |       0 | 000.0 | 0000 | 0000 | 0000 | 0000 | 0000 | 0000 | 00 | 00 | 991 |  0 |

The fixed columns are:

| Column  | Description                                                      |
|---------+------------------------------------------------------------------|
| M/R     | M = real-time measurement, R = record retrieved from memory      |
| Plot No | Plot number, 0-99                                                |
| Rec No  | Record number within the plot, 1-9999                            |
| Day     | Day of month, 1-31                                               |
| Mo      | Month, 1-12                                                      |
| Hr      | Hour in 24-hour format, 0-23                                     |
| Min     | Minute, 0-59                                                     |
| COâ‚‚ Ref | COâ‚‚ concentration in ppm (equivalent to Âµmol molâ»Â¹)              |
| Hâ‚‚O Ref | Water vapor in millibars (only if optional RH sensor is fitted)  |
| RHT     | Temperature from RH sensor in Â°C (if sensor is fitted)           |
| A-H     | Probe-specific fields (see probe type table below)               |
| AP      | Atmospheric pressure in millibars                                |
| PT      | Probe type code, 0-11                                            |

Columns A through H contain probe-specific data whose meaning depends on the connected sensor:

| Type | Sensor                  | A         | B         | C        | D        | E        | F          | G              | H           |
|------+-------------------------+-----------+-----------+----------+----------+----------+------------+----------------+-------------|
|    0 | No Sensor (stand-alone) | mV Pin 1  | mV Pin 2  | mV Pin 3 | mV Pin 4 | mV Pin 5 | â€”          | â€”              | â€”           |
|    1 | STP-1 Soil Temp         | PAR       | %RH       | Temp     | â€”        | mV Pin 5 | â€”          | â€”              | â€”           |
|    2 | HTR-2 %RH/Temp/PAR      | PAR       | %RH       | Temp     | â€”        | â€”        | â€”          | â€”              | â€”           |
|    3 | HTR-1 %RH/Temp/LUX      | PAR       | %RH       | Temp     | â€”        | â€”        | â€”          | â€”              | â€”           |
|    7 | PMR-4 Porometer         | PAR       | %RH In    | Temp     | %RH Out  | Flow     | GS         | â€”              | â€”           |
|    8 | SRC-1 Soil Respiration  | PAR       | %RH       | Temp     | DC       | DT       | SR Rate    | â€”              | +/- SR Rate |
|   10 | 50Y %RH/Temp            | â€”         | %RH       | Temp     | â€”        | â€”        | â€”          | â€”              | â€”           |
|   11 | CFX-1 / CPY-3           | PAR       | Evap Rate | Temp     | DC       | Flow     | SR Rate    | Flow Mult.     | +/- SR Rate |

The units for each data type are:

| Output Data | Units                                                       |
|-------------+-------------------------------------------------------------|
| PAR         | Âµmol mâ»Â² sâ»Â¹                                                |
| %RH         | %                                                           |
| Evap Rate   | mmol mâ»Â² sâ»Â¹ Ã— 1000                                         |
| Temperature | Â°C                                                          |
| Flow        | ml minâ»Â¹                                                    |
| GS          | mmol (Hâ‚‚O) mâ»Â² sâ»Â¹ (Stomatal Conductance)                   |
| SR Rate     | g COâ‚‚ mâ»Â² hrâ»Â¹ for SRC-1; Âµmol mâ»Â² sâ»Â¹ for CPY-3 and CFX-1 |
| DC          | ppm (change in COâ‚‚ concentration)                           |
| DT          | seconds (change in time)                                    |
| +/-         | 00 = respiration (COâ‚‚ increase), 01 = uptake (COâ‚‚ decrease) |

#+attr_shortcode: Note
#+begin_alert2
For CFX-1/CPY-3, column G contains a flow multiplier (1 or 10) that should be applied to get the true flow rate.
#+end_alert2

Here's a Python function that parses a raw 61-character record:

#+BEGIN_SRC python
def parse_egm4_record(raw):
    """Parse EGM-4 61-character fixed-width record (1 letter + 60 digits).
    
    Example input: 'R000002180313170042900000000000000000000000000400000000096508'
    """
    return {
        'mode': raw[0],              # 1 char: M or R
        'plot': int(raw[1:3]),       # 2 chars: 00-99
        'record_num': int(raw[3:7]), # 4 chars: 0001-9999
        'day': int(raw[7:9]),        # 2 chars
        'month': int(raw[9:11]),     # 2 chars
        'hour': int(raw[11:13]),     # 2 chars
        'minute': int(raw[13:15]),   # 2 chars
        'co2_ppm': int(raw[15:19]),  # 4 chars
        'h2o_mb': int(raw[19:23]),   # 4 chars
        'rht_temp': float(raw[23:28]) / 10,  # 5 chars (XXX.X format)
        'sensor_a': int(raw[28:32]), # 4 chars
        'sensor_b': int(raw[32:36]), # 4 chars
        'sensor_c': int(raw[36:40]), # 4 chars
        'sensor_d': int(raw[40:44]), # 4 chars
        'sensor_e': int(raw[44:48]), # 4 chars
        'sensor_f': int(raw[48:52]), # 4 chars
        'sensor_g': int(raw[52:54]), # 2 chars
        'sensor_h': int(raw[54:56]), # 2 chars
        'pressure_mb': int(raw[56:59]),  # 3 chars
        'probe_type': int(raw[59:61])    # 2 chars (types 0-11)
    }
#+END_SRC

Beyond data records, the EGM-4 also sends status messages during startup and operation. A boot message takes the form ~B,EGM4,<serial>,<firmware>~ and provides the device's serial number and firmware version. During warmup, you'll see ~W,TT~ messages where TT indicates the current cell temperature. The instrument sends ~I,NN~ during initialization and ~Z,NN~ during zeroing, where NN is a countdown counter. Diagnostic messages beginning with ~D,~ contain internal state information documented in the manual on page 38.

*** B: Flux Calculation Methods

The EGM-4 calculates soil respiration flux automatically, but understanding the underlying mathematics helps with interpreting results and troubleshooting anomalies.

**** Closed-System Chamber Method

When using the SRC-1 chamber, flux is calculated from the rate at which COâ‚‚ accumulates inside the sealed volume. The fundamental equation is:

$$F = \frac{dC}{dt} \times \frac{V}{A} \times \frac{P}{R \times T}$$

In this equation, $F$ represents the COâ‚‚ flux in Âµmol mâ»Â² sâ»Â¹, $\frac{dC}{dt}$ is the rate of COâ‚‚ concentration change in ppm per second, $V$ is the total system volume (chamber plus tubing) in milliliters, and $A$ is the soil area covered by the chamber in square centimeters. The term $\frac{P}{RT}$ converts the concentration change to molar units, where $P$ is atmospheric pressure in Pascals, $R$ is the gas constant (8.314 J molâ»Â¹ Kâ»Â¹), and $T$ is air temperature in Kelvin.

The EGM-4 reports flux in g COâ‚‚ mâ»Â² hrâ»Â¹. The conversion from Âµmol mâ»Â² sâ»Â¹ involves multiplying by the molecular weight of COâ‚‚ (44.01 g/mol), converting micromoles to moles (Ã— 10â»â¶), and converting seconds to hours (Ã— 3600):

$$F_{g/mÂ²/hr} = F_{Âµmol/mÂ²/s} \times 44.01 \times 10^{-6} \times 3600$$

**** Linear vs. Quadratic Fitting

The EGM-4 offers two methods for determining the rate of COâ‚‚ change over time. 

Linear fitting assumes a constant flux rate throughout the measurement period. The instrument fits the data to the equation $C(t) = C_0 + kt$, where the slope $k$ equals $\frac{dC}{dt}$. This approach works well for short measurements under two minutes.

Quadratic fitting accounts for non-linear effects such as chamber leakage and feedback from rising COâ‚‚ concentrations. The instrument fits a curve of the form $C(t) = C_0 + kt + ct^2$, using the initial slope $k$ for the flux calculation. This method is recommended for measurements longer than two minutes. The EGM-4 automatically selects quadratic fitting when the coefficient $c$ exceeds 0.1 times $k$; otherwise, it defaults to linear.

**** Chamber Corrections

For the SRC-1, the default chamber volume is 1171 ml with a soil contact area of 78.5 cmÂ² (corresponding to the 10 cm diameter opening). Tubing typically adds 50â€“100 ml to the total volume. If you're using a custom chamber setup, the total volume is simply the chamber volume plus the tubing volume, where tubing volume can be calculated as $V_{tubing} = \pi r^2 L$ with $r$ being the internal radius and $L$ the total length in centimeters.

Temperature should ideally be measured inside the chamber using the RH/Temp sensor or an STP-1 probe, as the sample air temperature directly affects the flux calculation. The EGM-4 measures atmospheric pressure internally and applies corrections automatically. At higher elevations, pressure drops significantlyâ€”approximately 900 mb at 1000 m and 800 mb at 2000 m compared to 1013 mb at sea levelâ€”and this affects how many COâ‚‚ molecules occupy a given volume.

**** Worked Example

Flux is measured by placing a closed chamber on the soil and monitoring the rate of COâ‚‚ concentration increase inside the chamber. Assuming a well-mixed, sealed system:

$$R = \frac{(C_n - C_0)}{T_n} \times \frac{V}{A}$$

where $R$ is the flux (COâ‚‚ per unit area per unit time), $C_0$ is the initial COâ‚‚ concentration, $C_n$ is the concentration after time $T_n$, $V$ is the total system volume, and $A$ is the exposed soil area.

Over short measurement periods with small concentration changes relative to soil COâ‚‚ levels, flux should be constant, giving a linear concentration increase. However, any chamber leakage causes the apparent flux to decrease with time, producing a curved response. Fitting a quadratic equation $C = a + bT + cT^2$ between concentration and time allows extraction of the true initial flux rate.

Since $\frac{dC}{dT} = b + 2cT$, at time $T = 0$ we have $\frac{dC}{dT} = b$. This gives the instantaneous flux rate before leakage effects accumulate and become a problem. Comparing the magnitude of $cT$ to $b$ indicates leakage severityâ€”the EGM will yell ~NON LINEAR FIT~ at you if $cT$ exceeds 20% of $b$.

From the basic equation, $R = b \times \frac{V}{A}$. To express flux in mass per unit area per unit time, the rate $b$ must be in mass per unit volume. The COâ‚‚ analyzer measures volume/volume ratio (ppm by volume = ÂµL/L = Âµbar/bar = Âµmol/mol).

One kilogram-mole of gas (44.01 kg of COâ‚‚) occupies 22.41 mÂ³ at STP. The full conversion equation is:

$$R = b \times \frac{P}{1000} \times \frac{273}{273 + T_a} \times \frac{44.01}{22.41} \times \frac{V}{A}$$

where $R$ is flux in kg mâ»Â² sâ»Â¹, $b$ is measured as ppm sâ»Â¹, $P$ is atmospheric pressure in mb, $T_a$ is air temperature in Â°C, $V$ is system volume in mÂ³, and $A$ is exposed area in mÂ².

In practice, the EGM measures $\frac{dC}{dt}$ in ppm/second, $V$ in cmÂ³, and $A$ in cmÂ². Results are expressed as g mâ»Â² hrâ»Â¹. To convert g mâ»Â² hrâ»Â¹ to Âµmol mâ»Â² sâ»Â¹, multiply by 6.312.

*Environmental correction notes:*

/Water Vapor:/ Adding water vapor to dry air dilutes the COâ‚‚ concentration because the total air volume increases. From an infrared measurement perspective, water vapor induces a slight increase in COâ‚‚ absorption (foreign gas broadening) that approximately cancels the dilution effect. The net result is that the analyzer reports approximately the dry-gas concentration.

/Atmospheric Pressure:/ Increased pressure raises concentration according to the Gas Law, but infrared absorption increases more than expected due to pressure broadening of absorption bands. The approximate correction is:

$$C = C_M \times \frac{1000}{0.75P + 0.00025P^2}$$

where $C$ is the concentration that would be measured at 1000 mb and $C_M$ is the concentration measured at $P$ mb.

/Air Temperature:/ With the EGM's thermostatted detector at 45Â°C, the primary temperature effect is on gas density, following the Gas Law (approximately âˆ’0.3% per Â°C increase). The correction referenced to calibration at 0Â°C is:

$$C = C_M \times \frac{273 + T_a}{273}$$

When all corrections are applied, the complete equation becomes:

$$R = b \times \frac{1000}{1000} \times \frac{1000}{P(0.75 + 0.00025P)} \times \frac{273 + T_a}{273} \times \frac{273}{273 + T_a} \times \frac{44.01}{22.41} \times \frac{V}{A}$$

Simplifying:

$$R = \frac{b \times 44.01 \times V}{(0.75 + 0.00025P) \times 22.41 \times A}$$

The temperature corrections cancel, and the pressure effect is small. When calibrating at high altitude, the simplified form uses average atmospheric pressure at that altitude:

$$R = b \times \frac{P_{av}}{1000} \times \frac{44.01}{22.41} \times \frac{V}{A}$$

#+attr_shortcode: caution
#+begin_alert2
Measurement accuracy can be compromised by chamber leaks (which typically cause underestimation), temperature gradients inside the chamber (particularly when exposed to direct sunlight), pressure fluctuations from wind or weather changes, and non-representative soil coverage due to stones or gaps in the collar seal. Make sure your blue tac is firmly pressed into place.
#+end_alert2


*** C: Probe Types Reference (0-11)

The EGM-4 automatically identifies connected sensors by reading a code resistor on Pin 1 of the 15-pin connector. When you power on the device with a sensor attached, the startup screen displays "PROBETYPE X" where X is the detected type number from the table below:

| Type | Sensor/Probe                  | Code Resistor | Typical Use                              |
|------+-------------------------------+---------------+------------------------------------------|
|    0 | No sensor                     | None          | Stand-alone COâ‚‚ analyzer                 |
|    1 | STP-1 Soil Temperature        | 100 kÎ©        | Soil temperature logging                 |
|    2 | HTR-2 RH/Temp/PAR             | 56 kÎ©         | Environmental monitoring                 |
|    3 | HTR-1 RH/Temp/PAR             | 36 kÎ©         | Environmental monitoring (legacy)        |
|    4 | PAR-1 Light Sensor            | 27 kÎ©         | PAR (photosynthetically active radiation)|
|    5 | PAR-1 LUX                     | 20 kÎ©         | Light intensity in lux                   |
|    6 | SRM-1                         | 15 kÎ©         | Solarimeter                              |
|    7 | PMR-4 Porometer               | User-set      | Leaf stomatal conductance                |
|    8 | SRC-1 Soil Respiration        | 9.1 kÎ©        | Closed-system soil COâ‚‚ flux              |
|    9 | RH/T/Oâ‚‚                       | 20 kÎ©         | Humidity, temp, oxygen                   |
|   10 | 50Y RH/Temperature            | 5.6 kÎ©        | Humidity and temperature only            |
|   11 | CFX-1 / CPY-3                 | 4.3 kÎ©        | Open-system flux chambers                |

For Type 2, 3, and 10 sensors, the raw millivolt readings can be converted to physical units using these relationships: PAR equals the millivolt reading multiplied by 3 (giving Âµmol mâ»Â² sâ»Â¹), relative humidity equals the millivolt reading divided by 10 (giving percent), and temperature equals the millivolt reading divided by 20 (giving Â°C).

If you're using non-PP-Systems sensors or need to override auto-detection (for Type 0 or 7), you can manually set the probe type through Menu 2 (SET), then option 1 (EGM), where you select stand-alone mode, probe mode, or porometer mode.

Custom sensors can be connected to the I/O ports, which accept 0â€“1V input signals. The readings appear as millivolt values (0â€“1000 mV) in the A through E fields of data records. When using custom sensors, ensure your output is scaled to the 0â€“1V range and apply your own conversion factors during post-processing.

*** D: Water Vapor & Temperature Corrections

COâ‚‚ measurements are affected by both water vapor and temperature. The EGM-4 applies corrections automatically when appropriate sensors are connected, but understanding these effects helps in troubleshooting anomalous readings.

Water vapor dilutes the mole fraction of COâ‚‚ in air. The relationship between wet and dry COâ‚‚ concentrations is:

$$C_{dry} = \frac{C_{wet}}{1 - \frac{e}{P}}$$

Here, $C_{dry}$ is the COâ‚‚ concentration in dry air (ppm), $C_{wet}$ is the measured concentration in humid air, $e$ is water vapor pressure in millibars, and $P$ is total atmospheric pressure in millibars.

As a practical example: if you measure 400 ppm COâ‚‚ in air with 20 mb of water vapor at 1013 mb total pressure, the correction factor is $1 - (20/1013) = 0.980$, giving a dry-air equivalent of $400 / 0.980 = 408$ ppm. The EGM-4 applies this correction automatically when an RH/Temp sensor is connected; without the sensor, no correction is applied.

Temperature affects COâ‚‚ measurements in several ways. Colder air has higher gas density (more molecules per unit volume), detector sensitivity varies with temperature, and temperature is a direct input to flux calculations. To minimize temperature effects on the IRGA itself, the EGM-4 thermostatically maintains the sample cell at 55Â°C.

For best results, always use an RH/Temp sensor for accurate measurements, record the temperature inside the chamber (using an STP-1 if available) for flux calculations, and expect 2â€“4% corrections to COâ‚‚ values when humidity exceeds 90%.

*** E: Chamber Volume Calculations

Accurate flux measurements depend on knowing the total system volume, which includes both the chamber and all connecting tubing. For the SRC-1, the manufacturer specifies a chamber volume of 1171 ml. Adding the standard tubing (typically 50â€“100 ml depending on length) gives a total system volume of roughly 1220â€“1270 ml.

For cylindrical chambers, volume is calculated as $V = \pi r^2 h$, where $r$ is the radius and $h$ is the height, both in centimeters, yielding volume in cubic centimeters (equivalent to milliliters). Tubing volume uses the same formula: $V_{tube} = \pi r^2 L$, where $L$ is the total tubing length.

As an example, 1/8" inner diameter tubing has an internal diameter of 3.175 mm, or a radius of 0.15875 cm. For 100 cm of this tubing, the volume is $\pi \times (0.15875)^2 \times 100 = 7.9$ ml.

The soil contact area is similarly calculated as $A = \pi r^2$. For the SRC-1 with its 10 cm diameter opening, this gives $A = \pi \times 5^2 = 78.5$ cmÂ².

To enter custom volume and area values in the EGM-4, press 1 (REC) from the Main Menu, then press N at the settings screen to modify values. Press 1 to change volume or 2 to change area, enter your new values, and the EGM-4 will automatically update the V/A ratio used in flux calculations.

The volume-to-area ratio determines how quickly COâ‚‚ accumulates for a given flux rate. A high V/A ratio means slower accumulation and longer measurement times, while a low V/A ratio results in faster accumulation. For soil respiration work, typical V/A ratios are around 15 cm; the SRC-1 default is 14.9 cm.

*** F: open-egm4 Software Design Philosophy

This section explains why open-egm4 was built as a terminal user interface (TUI) and how the software works internally.

**** Why a Terminal Interface?

I deliberately chose to use a text-based interface instead of a graphical interface for several reasons. 

Chiefly, keep it simple, stupid. Additionally, it makes cross-platform support automatic, while the previous PP Systems software was Windows-only. It also eliminates dependencies on GUI toolkits, which can be a pain to install and maintain. It allows for remote access via SSH, which could theoretically be useful. I guess. A terminal interface is inherently scriptable and automatable, and it's much easier to fix if something goes wrong.

**** Advantages Over Legacy Windows Software

The official PP Systems software is Windows-only and has several limitations. It requires specific .NET framework versions that may conflict with other software, offers no remote access capability, and is closed-source. It also is no longer maintained. 

Open-egm4 meets and exceeds all of the featues that the official software has to offer.

Open-egm4 addresses all of these concerns. It runs on any operating system, is open source under the MIT license, and is actively developed and maintained. The community can contribute features, and it works seamlessly over SSH for remote field sites.

*Architecture Overview:*

Open-egm4 is built in Python using the [[https://textual.textualize.io/][Textual]] framework for terminal UI rendering.

The core serial communication lives in ~src/egm_interface.py~, which defines the ~EGM4Serial~ class. This class manages the connection to the EGM-4 via pyserial, parses the incoming 60-character fixed-width data records using position-based slicing, and dispatches parsed data to registered callbacks. The parser handles all probe types (0-11) and extracts fields like COâ‚‚, temperature, humidity, and calculated flux depending on the connected sensor.

Session persistence is handled by ~src/database.py~, which uses SQLite to store readings across sessions. This allows users to close the app and resume later without losing data. The database stores each reading with its timestamp, plot number, channel values, and session metadata.

The TUI itself is composed of screens and widgets in the ~src/tui/~ directory. The main application entry point is ~src/tui/app.py~, which sets up the Textual app and manages screen transitions. Key screens include the connection screen (~screens/connect.py~), the main monitor screen (~screens/monitor.py~), the export wizard (~screens/export.py~), and the high-visibility "big mode" (~screens/big_mode.py~).

The monitor screen orchestrates real-time display by wiring the serial handler to the chart widget (~widgets/co2_chart.py~), which renders data using [[https://github.com/piccolomo/plotext][plotext]] for ASCII plotting. Statistics are calculated and displayed by ~widgets/stats.py~, and the channel legend is managed by ~widgets/legend.py~.

Export functionality converts session data to CSV format, allowing users to filter by plot number and date range before saving.

*Data Flow:*
#+BEGIN_EXAMPLE
EGM-4 â†’ Serial Cable â†’ USB Adapter â†’ pyserial â†’ EGM4Serial (egm_interface.py)
                                                         â†“
                                                    Parser (position-based slicing)
                                                         â†“
                                               MonitorScreen (monitor.py)
                                                â†™         â†“         â†˜
                                          CO2Chart   StatsWidget   Database
                                                                      â†“
                                                               CSV Export
#+END_EXAMPLE

/Created in Doom Emacs 2.0.9, using org-mode 9.7./

/Written in January 2026./

Created by Morgan Salisbury ðŸ˜ŠðŸ‡â›µï¸ðŸ”ï¸â¤ï¸
* TODO About
:PROPERTIES:
:EXPORT_FILE_NAME: Creating-this-website
:END:
** Writing and formatting
All posts are written in Emacs 29.4 in Org mode.
** Publishing
Posts are published to markdown using ox-hugo, and pushed to GitHub using Magit. Hugo is used as a framework for the website, with a modified version of the papermod theme. Cloudflare pages is used for building the site.

Written in Emacs 29.4, using Doom 2.0.9, in Org mode 9.7. Published to markdown using ox-hugo, and pushed to GitHub using Magit. Hugo is used as the website framework with a modified version of the papermod theme. Cloudflare is used for domain management, and Cloudflare pages builds the site.
