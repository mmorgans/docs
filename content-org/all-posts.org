#+hugo_base_dir: ../

* DONE Setting up rgee                                             :rgee:R:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: setting-up-rgee
:END:

**  Introduction

From the [[https://github.com/r-spatial/rgee][rgee github page]]: "rgee is an R binding package for calling Google Earth Engine API from within R. Various functions are implemented to simplify the connection with the R spatial ecosystem."

This guide assumes use of RStudio on a Mac, but I personally use Emacs with ESS and found it to work wonderfully. Any Unix based system should work similarly. Windows should theoretically work by following the below, but more work might be required and I haven't tested it.

** Prerequisites

- R and RStudio (or other IDE)
- Google Earth Engine account.
  - Create a GEE project to work in.
- A healthy mindset ðŸ˜Š

** Installation

Install rgee, geojsonio and miniconda.

#+begin_src R
install.packages('rgee')
install.packages('reticulate')
install.packages('geojsonio')
reticulate::install_miniconda()
#+end_src

** Setup

Load the packages.

#+begin_src R
library(rgee)
library(geojsonio)
library(reticulate)
#+end_src

Install dependencies and double check to make sure everything is up to date.

#+begin_src R
rgee::ee_install()
rgee::ee_install_upgrade()
#+end_src

By this point, you should be ready to initialize rgee. To double check everything is ready, run a
#+begin_src R
ee_check()
#+end_src
to make sure. /Note: If the previous command complains about an argument being of length zero, it should be fine to ignore it and carry on./


** Initializing
If you haven't already, you will need to create a new project to work in. This process is semi annoying if you haven't already done it before, full disclaimer.

Navigate over to [[https://code.earthengine.google.com][the GEE code editor]] and click on your profile picture in the top right. Click "Register a new Cloud Project". Assuming this is correct, click "Register a Noncommercial or Commercial project" and then select "Unpaid usage". Select the relevent project type in the dropdown menu.

On the next screen, choose "Create a new Google Cloud Project". You can leave the Organization field blank, but you will need to at the least choose a project ID. I usually name my projects with the *ee-username-rgee-#*, where username is my username and # is a number. Note that creating the project can take a while. Don't refresh the page, as you will be forced to go through the above process again.

Once you've confirmed your project's information, you will be redirected to the GEE online code editor, where you can close the tab.

Moving back into the IDE, we can now initialize rgee.
#+begin_src R
ee_Initialize()
#+end_src

This should launch a page in your web browser where you can log in and select the project you created to link to rgee. Make sure to choose "Select an existing project" and select it.

If that didn't work, or threw you an error, don't panic. I had enormous amounts of trouble getting rgee to initialize properly. If this is the case for you, you can instead run the below two commands, which does the same thing.

/Note that you will need to replace the project name with your own./
#+begin_src R
ee$Authenticate(auth_mode='localhost')
ee$Initialize(project='YOUR-PROJECT-NAME')
#+end_src

Optionally, check your connectivity to GEE to see if everything is setup correctly.
#+begin_src R
ee$String('Hello from the Earth Engine servers!')$getInfo()
#+end_src

If one of those methods worked, pop the champagne.

*At the start of every new R session where you want to use rgee, you will need to load and then initialize the package in order to use it.*

This should look something like this

#+begin_src R
library(rgee)
ee$Authenticate(auth_mode='localhost')
ee$Initialize(project='YOUR-PROJECT-NAME')
#+end_src

Remember to change the project name to the one you created earlier.

** Examples
*** Surface water occurrence
In this example, rgee is used to visualize global surface water occurrence using the JRC Global Surface Water dataset.

/Load and initialize rgee first!/
#+begin_src R
# Loads the dataset from JRC
gsw <- ee$Image("JRC/GSW1_1/GlobalSurfaceWater")
occurrence <- gsw$select("occurrence")

# Defines params to show surface water
VIS_OCCURRENCE <- list(
  min = 0,
  max = 100,
  palette = c("red", "blue")
)

# Makes a mask with said params
VIS_WATER_MASK <- list(
  palette = c("white", "black")
)

# Creates another mask that only shows areas w/ 90% water occurance
water_mask <- occurrence$gt(90)$selfMask()

# Sets the center of the map to Douglas County
Map$setCenter(-95.3, 38.91, 11)

# Adds both masks to the map
Map$addLayer(occurrence$updateMask(occurrence$divide(100)), VIS_OCCURRENCE, "Water Occurrence (1984-2018)") +
Map$addLayer(water_mask, VIS_WATER_MASK, "90% occurrence", FALSE)
{% endhighlight %}

#+end_src
*** May 28th 2019 Tornado

In this example, rgee is used to view the damage path from the 2019 EF4 tornado that touched down in central Douglas County.

/Load and initialize rgee first!/
#+begin_src R

# Defines an area around Douglas County.
aoi <- ee$Geometry$Rectangle(c(-95.3, 38.85, -95.22, 38.91))

# Defines the dates we are interested in.
start_date <- '2019-05-28'
end_date <- '2019-06-01'
pre_event_date <- '2019-05-20'

# Load Sentinel-2 data for said dates.
s2_collection <- ee$ImageCollection('COPERNICUS/S2')$
  filterDate(start_date, end_date)$
  filterBounds(aoi)

# Get the least cloudy image from the post-event period.
post_event_image <- s2_collection$sort('CLOUDY_PIXEL_PERCENTAGE')$first()

# Define params for said image.
viz_params <- list(
  bands = c('B4', 'B3', 'B2'),
  min = 0,
  max = 3000,
  gamma = 1.4
)

# Add the post-event image to the map.
Map$centerObject(aoi, 12)  # Zoom in to level 12 for better detail
Map$addLayer(post_event_image, viz_params, 'Post-Event Sentinel-2 Image')

# Load pre-event data for comparison.
pre_event_image <- ee$ImageCollection('COPERNICUS/S2')$
  filterDate(pre_event_date, start_date)$
  filterBounds(aoi)$
  sort('CLOUDY_PIXEL_PERCENTAGE')$first()


# Calculate NDVI for pre and post tornado.
pre_ndvi <- pre_event_image$normalizedDifference(c('B8', 'B4'))
post_ndvi <- post_event_image$normalizedDifference(c('B8', 'B4'))

# Find difference.
ndvi_diff <- post_ndvi$subtract(pre_ndvi)

# Define params for NDVI difference.
ndvi_viz_params <- list(min = -0.5, max = 0.5, palette = c('red', 'yellow', 'green'))

# Add NDVI diff. layer to map!
Map$addLayer(ndvi_diff, ndvi_viz_params, 'NDVI Difference')
{% endhighlight %}
#+end_src

* DONE Using variables in rgee                                             :rgee:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: using-variables-in-rgee
:END:
** Introduction

Google Earth Engine provides access to a bunch of geospatial datasets including satellite imagery, climate data and land cover classifications. These datasets, known as variables, are used to perform geospatial analyses.

** Calling variables
/Load and initialize rgee first!/

Define an area that you want to visualize. The easiest way of doing this is to define a rectangle with coordinates.

#+begin_src R
aoi <- ee$Geometry$Rectangle(c(-120.4, 34.5, -119.4, 35.5))
#+end_src

In this example, I'll use the MODIS land cover datasets.

#+begin_src R
landcover <- ee$ImageCollection("MODIS/061/MCD12Q1")$first()$select("LC_Type1")
#+end_src

Set some visualization parameters to control how the data is displayed.

#+begin_src R
landcover_viz <- list(
  min = 1,
  max = 17,
  palette = c("05450a", "086a10", "54a708", "78d203", "009900",
              "c6b044", "dcd159", "dade48", "fbff13", "b6ff05",
              "27ff87", "c24f44", "a5a5a5", "ff6d4c", "69fff8",
              "f9ffa4", "1c0dff")
)
#+end_src

Center the map on the area we are interested in, and add in the land cover layer using the parameters we defined above.

#+begin_src R
Map$centerObject(aoi,8)
Map$addLayer(landcover, landcover_viz, "Land Cover :)")
#+end_src
* DONE Making maps of variables with rgee                                             :rgee:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: Making-maps-of-variables-with-rgee
:END:
** Introduction

Raw data often needs to be transformed in order to do anything useful with it. Typically, transforming variables in GEE involves manipulating raw bands of imagery to create products like NDVI and EVI, or performing math operations with multiple datasets.

*** Dividing EVI by Precipitation
In this example, EVI is being divided by precipitation data for Kansas, and the result is mapped.

/Load and initialize rgee first!/
#+BEGIN_SRC R
library(rgee)
ee_Initialize()

# Define an area of interest (AOI) over Kansas
aoi <- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0))

# Load the Sentinel-2 image collection and calculate EVI
s2_collection <- ee$ImageCollection("COPERNICUS/S2")$
  filterDate('2020-06-01', '2020-08-31')$
  filterBounds(aoi)$
  map(function(image) {
    evi <- image$expression(
      '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',
      list('NIR' = image$select("B8"), 'RED' = image$select("B4"), 'BLUE' = image$select("B2"))
    )$rename("EVI")
    return(image$addBands(evi))
  })
evi_image <- s2_collection$select("EVI")$mean()$clip(aoi)

# Visualize EVI to ensure it's calculated correctly
evi_viz <- list(
  min = -1,
  max = 1,
  palette = c("brown", "yellow", "green")
)
Map$setCenter(-98.35, 38.5, 6)
Map$addLayer(evi_image, evi_viz, "EVI")

# Load the TerraClimate PPT (precipitation) dataset
ppt_dataset <- ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE")$
  filterDate('2020-01-01', '2020-12-31')$
  select("pr")$
  mean()$
  clip(aoi)

# Visualize PPT to ensure it's loaded correctly
ppt_viz <- list(
  min = 0,
  max = 2000,
  palette = c("blue", "white", "green")
)
Map$addLayer(ppt_dataset, ppt_viz, "Precipitation")

# Ensure the datasets align perfectly for each pixel
evi_resampled <- evi_image$reproject(crs = ppt_dataset$projection(), scale = 1000)
ppt_resampled <- ppt_dataset$reproject(crs = evi_image$projection(), scale = 1000)

# Divide EVI by PPT
evi_ppt_ratio <- evi_resampled$divide(ppt_resampled)

# Define visualization parameters for the ratio
evi_ppt_viz <- list(
  min = 0,
  max = 0.1,
  palette = c("blue", "white", "red")
)

# Add the EVI/PPT ratio layer
Map$addLayer(evi_ppt_ratio, evi_ppt_viz, "EVI/PPT Ratio")

#+END_SRC

*** Breakdown

**** Define the AOI, the state of Kansas.

#+BEGIN_SRC R
aoi <- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0))
#+END_SRC

**** Load and Filter Sentinel-2 Data

Next, we load the Sentinel-2 image collection, filter it for the summer months (June to August 2020), and calculate EVI for each image. EVI values are then averaged and clipped only to our AOI.

#+BEGIN_SRC R
s2_collection <- ee$ImageCollection("COPERNICUS/S2")$
  filterDate('2020-06-01', '2020-08-31')$
  filterBounds(aoi)$
  map(function(image) {
    evi <- image$expression(
      '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',
      list('NIR' = image$select("B8"), 'RED' = image$select("B4"), 'BLUE' = image$select("B2"))
    )$rename("EVI")
    return(image$addBands(evi))
  })
evi_image <- s2_collection$select("EVI")$mean()$clip(aoi)
#+END_SRC

**** First mapping of EVI

This is to make sure the current values are correct and being visualized correctly. I had a lot of trouble with this example in particular, so I am redundantly checking work as we go.

#+BEGIN_SRC R
evi_viz <- list(
  min = -1,
  max = 1,
  palette = c("brown", "yellow", "green")
)
Map$setCenter(-98.35, 38.5, 6)
Map$addLayer(evi_image, evi_viz, "EVI")
#+END_SRC

**** Loading precip data

We load precip data from TerraClimate, filter it for the year 2020, average values, and clip them.

#+BEGIN_SRC R
ppt_dataset <- ee$ImageCollection("IDAHO_EPSCOR/TERRACLIMATE")$
  filterDate('2020-01-01', '2020-12-31')$
  select("pr")$
  mean()$
  clip(aoi)
#+END_SRC

**** Visualize PPT to make sure it's correct

Again, I am visualizing the precipitation data to make sure it looks correct.

#+BEGIN_SRC R
ppt_viz <- list(
  min = 0,
  max = 2000,
  palette = c("blue", "white", "green")
)
Map$addLayer(ppt_dataset, ppt_viz, "Precipitation")
#+END_SRC

**** Make sure data is aligned

Before actually performing any operations on the data, making sure that both datasets are aligned correctly is important. Here I'm reprojecting both sets to the same scale and resolution.

#+BEGIN_SRC R
evi_resampled <- evi_image$reproject(crs = ppt_dataset$projection(), scale = 1000)
ppt_resampled <- ppt_dataset$reproject(crs = evi_image$projection(), scale = 1000)
#+END_SRC
**** Transform the data

Dividing the EVI by the precip to calculate the ratio.

#+BEGIN_SRC R
evi_ppt_ratio <- evi_resampled$divide(ppt_resampled)
#+END_SRC

**** Define viz params for mapping the new ratio


#+BEGIN_SRC R
evi_ppt_viz <- list(
  min = 0,
  max = 0.1,
  palette = c("blue", "white", "red")
)
Map$addLayer(evi_ppt_ratio, evi_ppt_viz, "EVI/PPT Ratio")
#+END_SRC
* DONE Exporting data to a CSV with rgee                                             :rgee:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: Exporting-data-to-a-csv-with-rgee
:END:
** Introduction

In general, exporting data to a .csv with rgee is pretty easy. The general gist of the process is:
- Define the area or points you are interested in
- Filter data
- Convert the results to a list, and
- Export to a csv.

** Example
/Make sure to load and initialize rgee first!/
#+BEGIN_SRC R
# Define an AOI over Kansas
aoi <- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0))

# Define sample points in the area
points <- ee$FeatureCollection(c(
  ee$Feature(ee$Geometry$Point(-98.5795, 39.8283), list(label = "1")),
  ee$Feature(ee$Geometry$Point(-97.5795, 38.8283), list(label = "2")),
  ee$Feature(ee$Geometry$Point(-96.5795, 37.8283), list(label = "3"))
))

# Grab an image from Sentinal 2 and calculate NDVI
s2_collection <- ee$ImageCollection("COPERNICUS/S2")$
  filterDate('2020-06-01', '2020-06-30')$
  filterBounds(aoi)$
  map(function(image) {
    ndvi <- image$normalizedDifference(c("B8", "B4"))$rename("NDVI")
    return(image$addBands(ndvi))
  })
ndvi_image <- s2_collection$select("NDVI")$mean()$clip(aoi)

# Grab NDVI values at the sample points
ndvi_values <- ndvi_image$reduceRegions(
  collection = points,
  reducer = ee$Reducer$mean(),
  scale = 30
)

# Convert the result to a list and then to a data frame
ndvi_list <- ndvi_values$getInfo()$features
ndvi_df <- do.call(rbind, lapply(ndvi_list, function(x) data.frame(
  label = x$properties$label,
  NDVI = x$properties$mean,
  lon = x$geometry$coordinates[1],
  lat = x$geometry$coordinates[2]
)))

# Save the data frame as a CSV
write.csv(ndvi_df, "ndvi_values_hello.csv", row.names = FALSE)
#+END_SRC

* DONE Getting data from AppEEARS and NOAA                                             :rgee:
CLOSED: [2024-08-13 Tue 11:37]
:PROPERTIES:
:EXPORT_FILE_NAME: Getting-data-from-AppEEARS-and-NOAA
:END:


** Data types (link to method of gathering)
- [[MAT][MAT (Mean Annual Temperature)]]
  - Average yearly temperature.
- [[MAP][MAP (Mean Annual Precipitation)]]
  - Average yearly precipitation.
- [[GPP][GPP (Gross Primary Productivity)]]
  - Total amount of energy captured by plants. Does not account for respiration losses.
- [[NPP][NPP (Net Primary Productivity)]]
  - Amount of energy that remains after plants have used some of the captured energy for their own respiration. Actual amount of new biomass that is available for consumption by other critters. NPP = GPP - Respiration
- [[PET][PET (Potential Evapotranspiration)]]
  - Amount of water that would be evaporated and transpired by vegetation if there was sufficient water available. Atmospheric demand for water.
- [[AET, ET][AET, ET (Actual Evapotranspiration)]]  - Actual amount of water that is evaporated from soil and transpired by vegetation. Less than or equal to PET. Depends on availability of water.
- [[DI][DI (Dryness Index)]]
  - PET / MAP
- [[EP][EP (Evaporation Potential)]]
  - 1 - (PET /MAP)
** Sites
This data was gathered from many sites across the globe. Sites were sorted with a RegionName, SiteName, and Pit.

| RegionName     | SiteName        | Pit          |
|----------------+-----------------+--------------|
| Calhoun        | R7              | R7P2         |
| Calhoun        | R2              | R2P1         |
| Calhoun        | R7              | R7P1         |
| Calhoun        | R8              | R8P1         |
| Calhoun        | R8              | R8P2.5       |
| Calhoun        | R8              | R8P2         |
| Calhoun        | R1              | R1C2         |
| Calhoun        | R1              | R1C3         |
| Calhoun        | R2              | R2H1         |
| Calhoun        | R7              | R7H1         |
| Calhoun        | R7              | R7H2         |
| Calhoun        | R8              | R8H1         |
| Calhoun        | R8              | R8H2.5       |
| Calhoun        | R8              | R8H2         |
| Luquillo       | ElVerde         | ElVerdeM     |
| Luquillo       | ElVerde         | ElVerdeR     |
| Luquillo       | ElVerde         | ElVerdeT     |
| Luquillo       | Icacos          | IcacosM      |
| Luquillo       | Icacos          | IcacosR      |
| Luquillo       | Icacos          | IcacosT      |
| Catalina       | MixedCon        | MC_M         |
| Catalina       | MixedCon        | MC_R         |
| Catalina       | MixedCon        | MC_T         |
| Catalina       | BigelowDesert   | B2D_M        |
| Catalina       | BigelowDesert   | B2D_R        |
| Catalina       | BigelowDesert   | B2D_T        |
| ReynoldsCr     | NorthBasalt     | NB_R         |
| ReynoldsCr     | NorthBasalt     | NB_T         |
| ReynoldsCr     | NorthLoess      | NL_T         |
| ReynoldsCr     | SWBasalt        | SWB_M        |
| ReynoldsCr     | SWBasalt        | SWB_T        |
| ReynoldsCr     | SWLoess         | SWL_T        |
| SouthernSierra | SJER            | SJER_M       |
| SouthernSierra | SJER            | SJER_R       |
| SouthernSierra | SJER            | SJER_T       |
| DukeFarm       | DukeFarm        | DFPasture    |
| EKS            | Ottawa          | EKSAgri      |
| EKS            | Welda           | EKSNative    |
| EKS            | Welda           | EKSPostAg    |
| KNZ            | KNZ             | KNZNative    |
| KNZ            | KNZ             | KNZAgri      |
| KNZ            | KNZ             | KNZPostAg    |
| HAY            | HAY             | HAYNative    |
| HAY            | HAY             | HAYAgri      |
| HAY            | HAY             | HAYPostAg    |
| TRB            | TRB             | TRBNative    |
| TRB            | TRB             | TRBAgri      |
| TRB            | TRB             | TRBAgriIrrig |
| TRB            | TRB             | TRBPostAg    |
| FRESCC         | CC1             | CC1_2020     |
| FRESCC         | CC2             | CC2_2020     |
| FRESCC         | CC2             | CC2_2022     |
| FRESCC         | CC3             | CC3_2021     |
| FRESCC         | CC3             | CC3_2022     |
| FRESCC         | CC4             | CC4_2021     |
| FRESCC         | CC5             | CC5_2021     |
| Konza          | GrassyToe       | GrToeN01B    |
| Konza          | WoodyToe        | WdToeN04D    |
| Konza          | GrassyBackslope | GrBackslN01B |
| Konza          | WoodyBackslope  | WdBackslN04D |
| Konza          | GrassySummit    | GrSummN01B   |
| Konza          | WoodySummit     | WdSummN04D   |
| HJAndrews      | WS01            | NF_Y_A       |
| HJAndrews      | WS01            | SF_Y_A       |
| HJAndrews      | WS02            | NF_O_A       |
| HJAndrews      | WS02            | SF_O_A       |
| HJAndrews      | WS03            | NF_O_A       |
| HJAndrews      | WS03            | NF_Y_A       |
| HJAndrews      | WS03            | SF_O_A       |
| HJAndrews      | WS03            | SF_Y_A       |
| Alps           | Glacier         | Alps1        |
| Alps           | GlacierRidge    | Alps2        |
| Alps           | Limestone       | Alps3        |
| Alps           | Gneiss          | Alps5        |
| Alps           | Alluvial        | Alps6        |
| NH             | ThompsonPasture | NH_TP        |
| NH             | ThompsonForest  | NH_TF        |
| NH             | OrganicPasture  | NH_OP        |
| NH             | OrganicForest   | NH_OF        |


** Process
*** MAT
Gathered mainly from [[https://www.ncei.noaa.gov/maps/annual/][NCEI at NOAA]].
- Turn on the "Annual Normals (2006-2020)" map layer, and disable the "Global Summary of the Year" layer.
- Put coords into floating search box, and find a station near enough to the site to be relevant.
- Click the wrench on "Annual Normals (2006-2020)", and use the rectangle tool to make a box around the station, just enough to select it.
- Select the station in the menu that appears on the left side of the page, and add to cart.
- In the new tab, click "Show List" under the "Data Types" text field.
- Type, filter, and select both "Annual average temperature mean" and "Annual precipitation totals"
- In the downloaded .csv, precip is labeled as ANN-PRCP-NORMAL, and temperature is labeled as ANN-TAVG-NORMAL.
*** MAP
Gathered mainly from [[https://www.ncei.noaa.gov/maps/annual/][NCEI at NOAA]].
- Turn on the "Annual Normals (2006-2020)" map layer, and disable the "Global Summary of the Year" layer.
- Put coords into floating search box, and find a station near enough to the site to be relevant.
- Click the wrench on "Annual Normals (2006-2020)", and use the rectangle tool to make a box around the station, just enough to select it.
- Select the station in the menu that appears on the left side of the page, and add to cart.
- In the new tab, click "Show List" under the "Data Types" text field.
- Type, filter, and select both "Annual average temperature mean" and "Annual precipitation totals"
- In the downloaded .csv, precip is labeled as ANN-PRCP-NORMAL, and temperature is labeled as ANN-TAVG-NORMAL.
*** NPP
NPP data is gathered from [[https://appeears.earthdatacloud.nasa.gov/][AppEEARS]].
- Navigate to Extract > Point, and make an account if you haven't.
- Start a new request.
- Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like /ID, Category, Lat, Long/.
  - You can alternatively upload a .csv with the same formatting, useful for large pulls.
- Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021.
- Scroll down to select layers to include in the sample.
- NPP is the first result. Make sure the data is yearly, not 8-day.
- Add other products if you wish, and submit the request.
- Depending on the size of the data requested, it can take up to a couple hours to process.
*** PET
PET data is gathered from [[https://appeears.earthdatacloud.nasa.gov/][AppEEARS]].
- Navigate to Extract > Point, and make an account if you haven't.
- Start a new request.
- Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like /ID, Category, Lat, Long/.
  - You can alternatively upload a .csv with the same formatting, useful for large pulls.
- Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021.
- Scroll down to select layers to include in the sample.
- Search for "Evapo yearly" select the first option.
- PET is labeled "PET", and AET is labeled "ET".
- Depending on the size of the data requested, it can take up to a couple hours to process.
*** AET, ET
AET data is gathered from [[https://appeears.earthdatacloud.nasa.gov/][AppEEARS]].
- Navigate to Extract > Point, and make an account if you haven't.
- Start a new request.
- Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like /ID, Category, Lat, Long/.
  - You can alternatively upload a .csv with the same formatting, useful for large pulls.
- Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021.
- Scroll down to select layers to include in the sample.
- Search for "Evapo yearly" select the first option.
- PET is labeled "PET", and AET is labeled "ET".
- Depending on the size of the data requested, it can take up to a couple hours to process.
*** DI
- DI and EP are calculated with PET and MAP products.
- PET / MAP
*** EP
- EP and Di are calculated with PET and MAP products.
- 1 - (PET / MAP)
*** GPP
GPP data is gathered from [[https://appeears.earthdatacloud.nasa.gov/][AppEEARS]].
- Navigate to Extract > Point, and make an account if you haven't.
- Start a new request.
- Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like /ID, Category, Lat, Long/.
  - You can alternatively upload a .csv with the same formatting, useful for large pulls.
- Set the dates. For this project, I was pulling from Jan 1, 2006 - Dec 31, 2021.
- Scroll down to select layers to include in the sample.
- GPP is only available in 8-day, which creates an extremely obnoxious problem - I solved this problem with an R script

- If you need to calculate yearly GPP for many different sites, the first script is intended for that purpose.
- If you only need to calculate yearly GPP for one single site, then scroll down for instructions.

** Initial .csv setup
- Before you begin, we will need to edit the excel file that AppEEARS gives us.
  - Keep only the needed columns: ID, Category, Latitude, Longitude, Date and GPP - Note that the actual GPP column is labeled something like "MOD17A2HGF_061_Gpp_500m"
    - There are many extra columns that you will need to delete.
    - Rename the GPP column to "GPP"
- Create a new column called "Year". The goal is to have this column have the year in YYYY format for every sample.
  - In the first cell (Should be E2 or F2), enter "=YEAR(D2)", where D2 refers to your date column. Change the cell type to "General" - you should see a year in YYYY format.
  - Extend this formula down to fill in the whole Year column.
  - Copy the whole column, and then Edit > Paste Special..., and select Values. This replaces the context dependent cells with ones that just have the year.
- The list of columns should be ID, Category, Latitude, Longitude, Date, Year, GPP.
- "appears.csv" refers to the downloaded .csv - either rename your file or change this to call in the file that contains the downloaded data.

***** Multiple sites

#+begin_src R
  library(dplyr)

  # sets initial df as the sanitzed, edited .csv
  df <- read.csv("appeears.csv", header = TRUE)

  # sets output to not be in scientific notation
  options(scipen = 999)

  # checking the df to make sure all good.
  # I had to mess around in excel a bit to get rid of empty rows at the bottom.
  head(df)
  tail(df)

  # set object to sum all the 8day GPP values
  summarized_data <- aggregate(GPP ~ Category + Year, data=df, sum, na.rm = TRUE)

  # The goal was to take the sum values and keep the Site and Pit labels
  #   in the sheet.
  names(summarized_data)[names(summarized_data) == "GPP"] <- "total_GPP"

  # Gets rid of duplicates for Category and Year rows.
  unique_rows <- df[!duplicated(df[, c("Category", "Year")]), ]

  # set object to merge the sum'd GPPs and the category and year
  summarized_all_data <- merge(unique_rows, summarized_data, by=c("Category", "Year"))

  # export a .csv with the above
  write.csv(summarized_all_data, "annual_gpp.csv", row.names=FALSE)

  # New goal: to average each sites GPP values across all the defined years 2006-2021
  # removed stray 2005 8day values from output .csv in excel
  df2 <- read.csv("annual_gpp.csv", header = TRUE)

  #checking df2
  head(df2)

  # ALERT!! I open the annual_gpp.csv here and rename columns to be "Pit" and "Site", accordingly.
  # adds mean of total_GPP, and sets that to be average_GPP
  average_GPP <- aggregate(total_GPP ~ Pit, data = df2, FUN = mean)

  # takes average_GPP value and merges it with all the label columns
  # sorts by Pit
  merged_data <- merge(average_GPP, df2[c("Site", "Pit", "Year", "Latitude", "Longitude")]
                       , by = "Pit")

  # removes duplicates
  merged_data <- merged_data[!duplicated(merged_data$Pit), ]

  #  exports a csv with all of that stuff. Hip Hip hooray
  write.csv(merged_data, file = "time_averaged_GPP.csv", row.names = FALSE)
    #+end_src

***** Single site
If you only are processing GPP data from one site, then some slight modifications are needed for the script to function.

#+begin_src R
library(dplyr)

# sets initial df as the sanitized, edited data
df <- read.csv("appeears.csv", header = TRUE)

# sets output to not be in scientific notation
options(scipen = 999)

# checking the df to make sure all good
head(df)
tail(df)

# set object to sum all the 8day GPP values
summarized_data <- aggregate(GPP ~ Year, data=df, sum, na.rm = TRUE)

# The goal was to take the sum values and keep the Site and Pit labels in the sheet
names(summarized_data)[names(summarized_data) == "GPP"] <- "total_GPP"

# Gets rid of duplicates for Year rows
unique_rows <- df[!duplicated(df$Year), ]

# set object to merge the summed GPPs and the year
summarized_all_data <- merge(unique_rows, summarized_data, by="Year")

# export a .csv with the above
write.csv(summarized_all_data, "annual_gpp.csv", row.names=FALSE)

# Read the exported .csv
df2 <- read.csv("annual_gpp.csv", header = TRUE)

# Checking df2
head(df2)

# Calculate the average of total_GPP for each combination of Latitude and Longitude
average_GPP <- aggregate(total_GPP ~ Latitude + Longitude, data = df2, FUN = mean)

# Rename the average GPP column
names(average_GPP)[names(average_GPP) == "total_GPP"] <- "average_GPP"

# Merge the average GPP values with the original data to keep all necessary columns
merged_data <- merge(average_GPP, df2[, c("ID", "Latitude", "Longitude", "Year")], by = c("Latitude", "Longitude"))

# Remove duplicates to ensure each Latitude-Longitude combination appears only once
merged_data <- merged_data[!duplicated(merged_data[, c("Latitude", "Longitude")]), ]

# Export a csv with the averaged GPP values
write.csv(merged_data, file = "final_averaged_GPP.csv", row.names = FALSE)
#+end_src

* TODO Mapping DI and EP with rgee :rgee:maps:
:PROPERTIES:
:EXPORT_FILE_NAME: Mapping-DI-and-EP-with-rgee
:END:

Hello Bro
