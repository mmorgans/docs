[{"content":"Introduction \u0026ldquo;Keyhole Markup Language\u0026rdquo;\n.kml files are useful for a number of reasons, namely storing pins, locations, polygons, images, and other GIS info. One of the easiest ways to make them is with Google Earth.\nYou can approach this in a couple of ways. Both the Earth website and the Google Earth Pro desktop app are usable.\nGoogle Earth Web Open Google Earth in a browser. Open the left hand side bar. It\u0026rsquo;s a little arrow in the middle of the left edge. Click the \u0026ldquo;+ New\u0026rdquo; button, select \u0026ldquo;Local KML file\u0026rdquo;, and click \u0026ldquo;Create\u0026rdquo;. You should see a new section, \u0026ldquo;Local KML files\u0026rdquo;, and your new project, \u0026ldquo;Untitled\u0026rdquo;. You can rename the project by clicking on the kebab menu while hovering on it, and clicking \u0026ldquo;Rename\u0026rdquo;. Click on the project to select it. To add a location to the project, navigate to it, and then click the \u0026ldquo;Save to project\u0026rdquo; button that appears in the card. Alternatively, you can use the pin / placemark tool (first on the left in the toolbar) and it will be automatically added to the selected project. You can rename the pin / placemark by either doing so when you initially place it, or by using the kebab menu in the project menu. Once you are done adding to your project, you can export by clicking the kebab menu on it, and then selecting \u0026ldquo;Export as KML file\u0026rdquo;. Google Earth Pro Open Google Earth Pro. Create a folder under Add \u0026gt; Folder. This is your project, so name it accordingly. Create placemarks with the placemark tool. They should be automatically placed into the new folder. You can drag other objects inside of the folder to add them to the project. Once you are done with the project, export it by right clicking on the folder and selecting \u0026ldquo;Save place as..\u0026rdquo; There are two options to save: a .kml and .kmz. If you don\u0026rsquo;t know what to use, select .kml. .kmz files are used to compress larger projects, typically ones that include images, but have some compatability issues. ","permalink":"http://localhost:1313/posts/creating-a-kml-from-a-project/","summary":"Introduction \u0026ldquo;Keyhole Markup Language\u0026rdquo;\n.kml files are useful for a number of reasons, namely storing pins, locations, polygons, images, and other GIS info. One of the easiest ways to make them is with Google Earth.\nYou can approach this in a couple of ways. Both the Earth website and the Google Earth Pro desktop app are usable.\nGoogle Earth Web Open Google Earth in a browser. Open the left hand side bar.","title":"Creating a .kml file from a Google Earth project"},{"content":" Note: I have a sneaking suspicion that trying this in Earth Engine proper using JS will significantly improve the results. The same goal attempted in rgee will remain available below, and a hopefully better JS version will appear above this in the coming days.\nRgee version Introduction Goal: create global maps showing Dryness Index and Evaporative Index in both 2012 and 2019, using rgee.\nThis was pretty tricky to get working. The primary challenge was visualizing the data in a way that was meaningful, and preventing extreme values from obfuscating the scale.\nScale values / min and max A major pain to get right. The values in the script below are still not correct and the product generated should not be used for any purpose other than general visualization. Google Earth Engine documentation provides estimated min and max values and scale, but using those results in seemingly useless visualizations. After trials, I found that the best visualization came from using max values of 4 for DI layers, and 2 for EI layers. Additionally, make sure to multiple all bands by 0.1 to account for scale.\nColor palette Another pinch point. At first, the map being dominated by extreme values seems like an issue that could be easily solved by using a more expansive color palette. In practice, this doesn\u0026rsquo;t work. Going from only three colors to over twenty just creates more range in the areas of the map where range actually exists, instead of creating it in the areas that are solidly either the min or the max.\nData statistics Interesting findings here that mostly reveal my own incompetence. Doing some light sniffing on the visualized values gives some very bizarre results: for both bands, the 50th percentile is 0. For EI, the 95th percentile is 0.662 and the 99th is 0.759. Similar values are present among both years and both DI and EI.\nScript # Load required libraries library(rgee) library(ggplot2) # Initialize rgee: see docs.mor-gan.com/posts/setting-up-rgee/#initializing ee_check() ee_install_upgrade() ee$Authenticate(auth_mode=\u0026#39;localhost\u0026#39;) ee$Initialize(project=\u0026#39;ee-pugbugdude\u0026#39;) # Define the years of interest years \u0026lt;- c(2012, 2019) # Function to load datasets for different years - continued with snippet below. load_dataset \u0026lt;- function(year) { ee$ImageCollection(\u0026#34;IDAHO_EPSCOR/TERRACLIMATE\u0026#34;)$ filter(ee$Filter$calendarRange(year, year, \u0026#34;year\u0026#34;))$ mean() } # Loads the dataset above for both defined years. dataset_2012 \u0026lt;- load_dataset(2012) dataset_2019 \u0026lt;- load_dataset(2019) # Function to select bands and scale properly # see developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_TERRACLIMATE#bands # for scaling info. get_scaled_bands \u0026lt;- function(dataset) { list( pet = dataset$select(\u0026#39;pet\u0026#39;)$multiply(0.1), aet = dataset$select(\u0026#39;aet\u0026#39;)$multiply(0.1), pr = dataset$select(\u0026#39;pr\u0026#39;) ) } # Sets the bands for both years bands_2012 \u0026lt;- get_scaled_bands(dataset_2012) bands_2019 \u0026lt;- get_scaled_bands(dataset_2019) # Calculate indices # DI (Dryness Index) = PET / PR # EI (Evaporative Index) = AET / PR calculate_indices \u0026lt;- function(bands) { list( dryness_index = bands$pet$divide(bands$pr)$rename(\u0026#34;Dryness_Index\u0026#34;), evap_index = bands$aet$divide(bands$pr)$rename(\u0026#34;Evaporative_Index\u0026#34;) ) } # Calculates indices for both years indices_2012 \u0026lt;- calculate_indices(bands_2012) indices_2019 \u0026lt;- calculate_indices(bands_2019) # Sets the palette to use for mapping. index_palette \u0026lt;- c(\u0026#34;blue\u0026#34;, \u0026#34;cyan\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;yellow\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;darkred\u0026#34;) # Function to put layers on the map for both years and bands # Uses variables set above # Why: It\u0026#39;s easier to be able to edit the palette, min, and max values # for all layers at once, rather than having to keep track of several different lines. visualize_layer \u0026lt;- function(image, title, min, max) { Map$addLayer( image, list(min = min, max = max, palette = index_palette), title ) } # Set min and max values for visualization. # IMPORTANT: These are very, very finicky to figure out. The min and max listed at # developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_TERRACLIMATE#bands # will result in a wonky, poorly visualized map. # The numbers used below are a best attempt effort that generates a product to be used purely for # visualization, not a particularly accurate one. I strongly encourage you to adjust them to see how the map changes. dryness_index_min \u0026lt;- 0 dryness_index_max \u0026lt;- 4 evap_index_min \u0026lt;- 0 evap_index_max \u0026lt;- 1.5 # Adds each of the layers to the map. # In RStudio, the map should open automatically in the viewer tab. # In other environments, the map should open in a browser tab. visualize_layer(indices_2012$dryness_index, \u0026#34;DI 2012\u0026#34;, dryness_index_min, dryness_index_max) visualize_layer(indices_2012$evap_index, \u0026#34;EI 2012\u0026#34;, evap_index_min, evap_index_max) # Add layers for 2019 visualize_layer(indices_2019$dryness_index, \u0026#34;DI 2019\u0026#34;, dryness_index_min, dryness_index_max) visualize_layer(indices_2019$evap_index, \u0026#34;EI 2019\u0026#34;, evap_index_min, evap_index_max) ","permalink":"http://localhost:1313/posts/mapping-di-and-ep-with-rgee/","summary":"Note: I have a sneaking suspicion that trying this in Earth Engine proper using JS will significantly improve the results. The same goal attempted in rgee will remain available below, and a hopefully better JS version will appear above this in the coming days.\nRgee version Introduction Goal: create global maps showing Dryness Index and Evaporative Index in both 2012 and 2019, using rgee.\nThis was pretty tricky to get working.","title":"Mapping DI and EP with rgee"},{"content":"Introduction In general, exporting data to a .csv with rgee is pretty easy. The general gist of the process is:\nDefine the area or points you are interested in Filter data Convert the results to a list, and Export to a csv. Example Make sure to load and initialize rgee first!\n# Define an AOI over Kansas aoi \u0026lt;- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0)) # Define sample points in the area points \u0026lt;- ee$FeatureCollection(c( ee$Feature(ee$Geometry$Point(-98.5795, 39.8283), list(label = \u0026#34;1\u0026#34;)), ee$Feature(ee$Geometry$Point(-97.5795, 38.8283), list(label = \u0026#34;2\u0026#34;)), ee$Feature(ee$Geometry$Point(-96.5795, 37.8283), list(label = \u0026#34;3\u0026#34;)) )) # Grab an image from Sentinal 2 and calculate NDVI s2_collection \u0026lt;- ee$ImageCollection(\u0026#34;COPERNICUS/S2\u0026#34;)$ filterDate(\u0026#39;2020-06-01\u0026#39;, \u0026#39;2020-06-30\u0026#39;)$ filterBounds(aoi)$ map(function(image) { ndvi \u0026lt;- image$normalizedDifference(c(\u0026#34;B8\u0026#34;, \u0026#34;B4\u0026#34;))$rename(\u0026#34;NDVI\u0026#34;) return(image$addBands(ndvi)) }) ndvi_image \u0026lt;- s2_collection$select(\u0026#34;NDVI\u0026#34;)$mean()$clip(aoi) # Grab NDVI values at the sample points ndvi_values \u0026lt;- ndvi_image$reduceRegions( collection = points, reducer = ee$Reducer$mean(), scale = 30 ) # Convert the result to a list and then to a data frame ndvi_list \u0026lt;- ndvi_values$getInfo()$features ndvi_df \u0026lt;- do.call(rbind, lapply(ndvi_list, function(x) data.frame( label = x$properties$label, NDVI = x$properties$mean, lon = x$geometry$coordinates[1], lat = x$geometry$coordinates[2] ))) # Save the data frame as a CSV write.csv(ndvi_df, \u0026#34;ndvi_values_hello.csv\u0026#34;, row.names = FALSE) ","permalink":"http://localhost:1313/posts/exporting-data-to-a-csv-with-rgee/","summary":"Introduction In general, exporting data to a .csv with rgee is pretty easy. The general gist of the process is:\nDefine the area or points you are interested in Filter data Convert the results to a list, and Export to a csv. Example Make sure to load and initialize rgee first!\n# Define an AOI over Kansas aoi \u0026lt;- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0)) # Define sample points in the area points \u0026lt;- ee$FeatureCollection(c( ee$Feature(ee$Geometry$Point(-98.","title":"Exporting data to a CSV with rgee"},{"content":"Data types (link to method of gathering) MAT (Mean Annual Temperature) Average yearly temperature. MAP (Mean Annual Precipitation) Average yearly precipitation. GPP (Gross Primary Productivity) Total amount of energy captured by plants. Does not account for respiration losses. NPP (Net Primary Productivity) Amount of energy that remains after plants have used some of the captured energy for their own respiration. Actual amount of new biomass that is available for consumption by other critters. NPP = GPP - Respiration PET (Potential Evapotranspiration) Amount of water that would be evaporated and transpired by vegetation if there was sufficient water available. Atmospheric demand for water. AET, ET (Actual Evapotranspiration) - Actual amount of water that is evaporated from soil and transpired by vegetation. Less than or equal to PET. Depends on availability of water. DI (Dryness Index) PET / MAP EP (Evaporation Potential) 1 - (PET /MAP) Sites This data was gathered from many sites across the globe. Sites were sorted with a RegionName, SiteName, and Pit.\nRegionName SiteName Pit Calhoun R7 R7P2 Calhoun R2 R2P1 Calhoun R7 R7P1 Calhoun R8 R8P1 Calhoun R8 R8P2.5 Calhoun R8 R8P2 Calhoun R1 R1C2 Calhoun R1 R1C3 Calhoun R2 R2H1 Calhoun R7 R7H1 Calhoun R7 R7H2 Calhoun R8 R8H1 Calhoun R8 R8H2.5 Calhoun R8 R8H2 Luquillo ElVerde ElVerdeM Luquillo ElVerde ElVerdeR Luquillo ElVerde ElVerdeT Luquillo Icacos IcacosM Luquillo Icacos IcacosR Luquillo Icacos IcacosT Catalina MixedCon MC_M Catalina MixedCon MC_R Catalina MixedCon MC_T Catalina BigelowDesert B2D_M Catalina BigelowDesert B2D_R Catalina BigelowDesert B2D_T ReynoldsCr NorthBasalt NB_R ReynoldsCr NorthBasalt NB_T ReynoldsCr NorthLoess NL_T ReynoldsCr SWBasalt SWB_M ReynoldsCr SWBasalt SWB_T ReynoldsCr SWLoess SWL_T SouthernSierra SJER SJER_M SouthernSierra SJER SJER_R SouthernSierra SJER SJER_T DukeFarm DukeFarm DFPasture EKS Ottawa EKSAgri EKS Welda EKSNative EKS Welda EKSPostAg KNZ KNZ KNZNative KNZ KNZ KNZAgri KNZ KNZ KNZPostAg HAY HAY HAYNative HAY HAY HAYAgri HAY HAY HAYPostAg TRB TRB TRBNative TRB TRB TRBAgri TRB TRB TRBAgriIrrig TRB TRB TRBPostAg FRESCC CC1 CC1_2020 FRESCC CC2 CC2_2020 FRESCC CC2 CC2_2022 FRESCC CC3 CC3_2021 FRESCC CC3 CC3_2022 FRESCC CC4 CC4_2021 FRESCC CC5 CC5_2021 Konza GrassyToe GrToeN01B Konza WoodyToe WdToeN04D Konza GrassyBackslope GrBackslN01B Konza WoodyBackslope WdBackslN04D Konza GrassySummit GrSummN01B Konza WoodySummit WdSummN04D HJAndrews WS01 NF_Y_A HJAndrews WS01 SF_Y_A HJAndrews WS02 NF_O_A HJAndrews WS02 SF_O_A HJAndrews WS03 NF_O_A HJAndrews WS03 NF_Y_A HJAndrews WS03 SF_O_A HJAndrews WS03 SF_Y_A Alps Glacier Alps1 Alps GlacierRidge Alps2 Alps Limestone Alps3 Alps Gneiss Alps5 Alps Alluvial Alps6 NH ThompsonPasture NH_TP NH ThompsonForest NH_TF NH OrganicPasture NH_OP NH OrganicForest NH_OF Process MAT Gathered mainly from NCEI at NOAA.\nTurn on the \u0026ldquo;Annual Normals (2006-2020)\u0026rdquo; map layer, and disable the \u0026ldquo;Global Summary of the Year\u0026rdquo; layer. Put coords into floating search box, and find a station near enough to the site to be relevant. Click the wrench on \u0026ldquo;Annual Normals (2006-2020)\u0026rdquo;, and use the rectangle tool to make a box around the station, just enough to select it. Select the station in the menu that appears on the left side of the page, and add to cart. In the new tab, click \u0026ldquo;Show List\u0026rdquo; under the \u0026ldquo;Data Types\u0026rdquo; text field. Type, filter, and select both \u0026ldquo;Annual average temperature mean\u0026rdquo; and \u0026ldquo;Annual precipitation totals\u0026rdquo; In the downloaded .csv, precip is labeled as ANN-PRCP-NORMAL, and temperature is labeled as ANN-TAVG-NORMAL. MAP Gathered mainly from NCEI at NOAA.\nTurn on the \u0026ldquo;Annual Normals (2006-2020)\u0026rdquo; map layer, and disable the \u0026ldquo;Global Summary of the Year\u0026rdquo; layer. Put coords into floating search box, and find a station near enough to the site to be relevant. Click the wrench on \u0026ldquo;Annual Normals (2006-2020)\u0026rdquo;, and use the rectangle tool to make a box around the station, just enough to select it. Select the station in the menu that appears on the left side of the page, and add to cart. In the new tab, click \u0026ldquo;Show List\u0026rdquo; under the \u0026ldquo;Data Types\u0026rdquo; text field. Type, filter, and select both \u0026ldquo;Annual average temperature mean\u0026rdquo; and \u0026ldquo;Annual precipitation totals\u0026rdquo; In the downloaded .csv, precip is labeled as ANN-PRCP-NORMAL, and temperature is labeled as ANN-TAVG-NORMAL. NPP NPP data is gathered from AppEEARS.\nNavigate to Extract \u0026gt; Point, and make an account if you haven\u0026rsquo;t. Start a new request. Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like ID, Category, Lat, Long. You can alternatively upload a .csv with the same formatting, useful for large pulls. Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021. Scroll down to select layers to include in the sample. NPP is the first result. Make sure the data is yearly, not 8-day. Add other products if you wish, and submit the request. Depending on the size of the data requested, it can take up to a couple hours to process. PET PET data is gathered from AppEEARS.\nNavigate to Extract \u0026gt; Point, and make an account if you haven\u0026rsquo;t. Start a new request. Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like ID, Category, Lat, Long. You can alternatively upload a .csv with the same formatting, useful for large pulls. Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021. Scroll down to select layers to include in the sample. Search for \u0026ldquo;Evapo yearly\u0026rdquo; select the first option. PET is labeled \u0026ldquo;PET\u0026rdquo;, and AET is labeled \u0026ldquo;ET\u0026rdquo;. Depending on the size of the data requested, it can take up to a couple hours to process. AET, ET AET data is gathered from AppEEARS.\nNavigate to Extract \u0026gt; Point, and make an account if you haven\u0026rsquo;t. Start a new request. Name the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like ID, Category, Lat, Long. You can alternatively upload a .csv with the same formatting, useful for large pulls. Set the dates. For this process, I was pulling from Jan 1, 2006 - Dec 31, 2021. Scroll down to select layers to include in the sample. Search for \u0026ldquo;Evapo yearly\u0026rdquo; select the first option. PET is labeled \u0026ldquo;PET\u0026rdquo;, and AET is labeled \u0026ldquo;ET\u0026rdquo;. Depending on the size of the data requested, it can take up to a couple hours to process. DI DI and EP are calculated with PET and MAP products. PET / MAP EP EP and Di are calculated with PET and MAP products. 1 - (PET / MAP) GPP GPP data is gathered from AppEEARS.\nNavigate to Extract \u0026gt; Point, and make an account if you haven\u0026rsquo;t.\nStart a new request.\nName the request, and put your coordinates in the text box on the right. Comma seperated, the text should look like ID, Category, Lat, Long.\nYou can alternatively upload a .csv with the same formatting, useful for large pulls. Set the dates. For this project, I was pulling from Jan 1, 2006 - Dec 31, 2021.\nScroll down to select layers to include in the sample.\nGPP is only available in 8-day, which creates an extremely obnoxious problem - I solved this problem with an R script\nIf you need to calculate yearly GPP for many different sites, the first script is intended for that purpose.\nIf you only need to calculate yearly GPP for one single site, then scroll down for instructions.\nInitial .csv setup Before you begin, we will need to edit the excel file that AppEEARS gives us. Keep only the needed columns: ID, Category, Latitude, Longitude, Date and GPP - Note that the actual GPP column is labeled something like \u0026ldquo;MOD17A2HGF_061_Gpp_500m\u0026rdquo; There are many extra columns that you will need to delete. Rename the GPP column to \u0026ldquo;GPP\u0026rdquo; Create a new column called \u0026ldquo;Year\u0026rdquo;. The goal is to have this column have the year in YYYY format for every sample. In the first cell (Should be E2 or F2), enter \u0026ldquo;=YEAR(D2)\u0026rdquo;, where D2 refers to your date column. Change the cell type to \u0026ldquo;General\u0026rdquo; - you should see a year in YYYY format. Extend this formula down to fill in the whole Year column. Copy the whole column, and then Edit \u0026gt; Paste Special\u0026hellip;, and select Values. This replaces the context dependent cells with ones that just have the year. The list of columns should be ID, Category, Latitude, Longitude, Date, Year, GPP. \u0026ldquo;appears.csv\u0026rdquo; refers to the downloaded .csv - either rename your file or change this to call in the file that contains the downloaded data. Multiple sites\nlibrary(dplyr) # sets initial df as the sanitzed, edited .csv df \u0026lt;- read.csv(\u0026#34;appeears.csv\u0026#34;, header = TRUE) # sets output to not be in scientific notation options(scipen = 999) # checking the df to make sure all good. # I had to mess around in excel a bit to get rid of empty rows at the bottom. head(df) tail(df) # set object to sum all the 8day GPP values summarized_data \u0026lt;- aggregate(GPP ~ Category + Year, data=df, sum, na.rm = TRUE) # The goal was to take the sum values and keep the Site and Pit labels # in the sheet. names(summarized_data)[names(summarized_data) == \u0026#34;GPP\u0026#34;] \u0026lt;- \u0026#34;total_GPP\u0026#34; # Gets rid of duplicates for Category and Year rows. unique_rows \u0026lt;- df[!duplicated(df[, c(\u0026#34;Category\u0026#34;, \u0026#34;Year\u0026#34;)]), ] # set object to merge the sum\u0026#39;d GPPs and the category and year summarized_all_data \u0026lt;- merge(unique_rows, summarized_data, by=c(\u0026#34;Category\u0026#34;, \u0026#34;Year\u0026#34;)) # export a .csv with the above write.csv(summarized_all_data, \u0026#34;annual_gpp.csv\u0026#34;, row.names=FALSE) # New goal: to average each sites GPP values across all the defined years 2006-2021 # removed stray 2005 8day values from output .csv in excel df2 \u0026lt;- read.csv(\u0026#34;annual_gpp.csv\u0026#34;, header = TRUE) #checking df2 head(df2) # ALERT!! I open the annual_gpp.csv here and rename columns to be \u0026#34;Pit\u0026#34; and \u0026#34;Site\u0026#34;, accordingly. # adds mean of total_GPP, and sets that to be average_GPP average_GPP \u0026lt;- aggregate(total_GPP ~ Pit, data = df2, FUN = mean) # takes average_GPP value and merges it with all the label columns # sorts by Pit merged_data \u0026lt;- merge(average_GPP, df2[c(\u0026#34;Site\u0026#34;, \u0026#34;Pit\u0026#34;, \u0026#34;Year\u0026#34;, \u0026#34;Latitude\u0026#34;, \u0026#34;Longitude\u0026#34;)] , by = \u0026#34;Pit\u0026#34;) # removes duplicates merged_data \u0026lt;- merged_data[!duplicated(merged_data$Pit), ] # exports a csv with all of that stuff. Hip Hip hooray write.csv(merged_data, file = \u0026#34;time_averaged_GPP.csv\u0026#34;, row.names = FALSE) Single site\nIf you only are processing GPP data from one site, then some slight modifications are needed for the script to function.\nlibrary(dplyr) # sets initial df as the sanitized, edited data df \u0026lt;- read.csv(\u0026#34;appeears.csv\u0026#34;, header = TRUE) # sets output to not be in scientific notation options(scipen = 999) # checking the df to make sure all good head(df) tail(df) # set object to sum all the 8day GPP values summarized_data \u0026lt;- aggregate(GPP ~ Year, data=df, sum, na.rm = TRUE) # The goal was to take the sum values and keep the Site and Pit labels in the sheet names(summarized_data)[names(summarized_data) == \u0026#34;GPP\u0026#34;] \u0026lt;- \u0026#34;total_GPP\u0026#34; # Gets rid of duplicates for Year rows unique_rows \u0026lt;- df[!duplicated(df$Year), ] # set object to merge the summed GPPs and the year summarized_all_data \u0026lt;- merge(unique_rows, summarized_data, by=\u0026#34;Year\u0026#34;) # export a .csv with the above write.csv(summarized_all_data, \u0026#34;annual_gpp.csv\u0026#34;, row.names=FALSE) # Read the exported .csv df2 \u0026lt;- read.csv(\u0026#34;annual_gpp.csv\u0026#34;, header = TRUE) # Checking df2 head(df2) # Calculate the average of total_GPP for each combination of Latitude and Longitude average_GPP \u0026lt;- aggregate(total_GPP ~ Latitude + Longitude, data = df2, FUN = mean) # Rename the average GPP column names(average_GPP)[names(average_GPP) == \u0026#34;total_GPP\u0026#34;] \u0026lt;- \u0026#34;average_GPP\u0026#34; # Merge the average GPP values with the original data to keep all necessary columns merged_data \u0026lt;- merge(average_GPP, df2[, c(\u0026#34;ID\u0026#34;, \u0026#34;Latitude\u0026#34;, \u0026#34;Longitude\u0026#34;, \u0026#34;Year\u0026#34;)], by = c(\u0026#34;Latitude\u0026#34;, \u0026#34;Longitude\u0026#34;)) # Remove duplicates to ensure each Latitude-Longitude combination appears only once merged_data \u0026lt;- merged_data[!duplicated(merged_data[, c(\u0026#34;Latitude\u0026#34;, \u0026#34;Longitude\u0026#34;)]), ] # Export a csv with the averaged GPP values write.csv(merged_data, file = \u0026#34;final_averaged_GPP.csv\u0026#34;, row.names = FALSE) ","permalink":"http://localhost:1313/posts/getting-data-from-appeears-and-noaa/","summary":"Data types (link to method of gathering) MAT (Mean Annual Temperature) Average yearly temperature. MAP (Mean Annual Precipitation) Average yearly precipitation. GPP (Gross Primary Productivity) Total amount of energy captured by plants. Does not account for respiration losses. NPP (Net Primary Productivity) Amount of energy that remains after plants have used some of the captured energy for their own respiration. Actual amount of new biomass that is available for consumption by other critters.","title":"Getting data from AppEEARS and NOAA"},{"content":"Introduction Raw data often needs to be transformed in order to do anything useful with it. Typically, transforming variables in GEE involves manipulating raw bands of imagery to create products like NDVI and EVI, or performing math operations with multiple datasets.\nDividing EVI by Precipitation In this example, EVI is being divided by precipitation data for Kansas, and the result is mapped.\nLoad and initialize rgee first!\nlibrary(rgee) ee_Initialize() # Define an area of interest (AOI) over Kansas aoi \u0026lt;- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0)) # Load the Sentinel-2 image collection and calculate EVI s2_collection \u0026lt;- ee$ImageCollection(\u0026#34;COPERNICUS/S2\u0026#34;)$ filterDate(\u0026#39;2020-06-01\u0026#39;, \u0026#39;2020-08-31\u0026#39;)$ filterBounds(aoi)$ map(function(image) { evi \u0026lt;- image$expression( \u0026#39;2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))\u0026#39;, list(\u0026#39;NIR\u0026#39; = image$select(\u0026#34;B8\u0026#34;), \u0026#39;RED\u0026#39; = image$select(\u0026#34;B4\u0026#34;), \u0026#39;BLUE\u0026#39; = image$select(\u0026#34;B2\u0026#34;)) )$rename(\u0026#34;EVI\u0026#34;) return(image$addBands(evi)) }) evi_image \u0026lt;- s2_collection$select(\u0026#34;EVI\u0026#34;)$mean()$clip(aoi) # Visualize EVI to ensure it\u0026#39;s calculated correctly evi_viz \u0026lt;- list( min = -1, max = 1, palette = c(\u0026#34;brown\u0026#34;, \u0026#34;yellow\u0026#34;, \u0026#34;green\u0026#34;) ) Map$setCenter(-98.35, 38.5, 6) Map$addLayer(evi_image, evi_viz, \u0026#34;EVI\u0026#34;) # Load the TerraClimate PPT (precipitation) dataset ppt_dataset \u0026lt;- ee$ImageCollection(\u0026#34;IDAHO_EPSCOR/TERRACLIMATE\u0026#34;)$ filterDate(\u0026#39;2020-01-01\u0026#39;, \u0026#39;2020-12-31\u0026#39;)$ select(\u0026#34;pr\u0026#34;)$ mean()$ clip(aoi) # Visualize PPT to ensure it\u0026#39;s loaded correctly ppt_viz \u0026lt;- list( min = 0, max = 2000, palette = c(\u0026#34;blue\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;green\u0026#34;) ) Map$addLayer(ppt_dataset, ppt_viz, \u0026#34;Precipitation\u0026#34;) # Ensure the datasets align perfectly for each pixel evi_resampled \u0026lt;- evi_image$reproject(crs = ppt_dataset$projection(), scale = 1000) ppt_resampled \u0026lt;- ppt_dataset$reproject(crs = evi_image$projection(), scale = 1000) # Divide EVI by PPT evi_ppt_ratio \u0026lt;- evi_resampled$divide(ppt_resampled) # Define visualization parameters for the ratio evi_ppt_viz \u0026lt;- list( min = 0, max = 0.1, palette = c(\u0026#34;blue\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;red\u0026#34;) ) # Add the EVI/PPT ratio layer Map$addLayer(evi_ppt_ratio, evi_ppt_viz, \u0026#34;EVI/PPT Ratio\u0026#34;) Breakdown Define the AOI, the state of Kansas. aoi \u0026lt;- ee$Geometry$Rectangle(c(-102.05, 36.99, -94.6, 40.0)) Load and Filter Sentinel-2 Data Next, we load the Sentinel-2 image collection, filter it for the summer months (June to August 2020), and calculate EVI for each image. EVI values are then averaged and clipped only to our AOI.\ns2_collection \u0026lt;- ee$ImageCollection(\u0026#34;COPERNICUS/S2\u0026#34;)$ filterDate(\u0026#39;2020-06-01\u0026#39;, \u0026#39;2020-08-31\u0026#39;)$ filterBounds(aoi)$ map(function(image) { evi \u0026lt;- image$expression( \u0026#39;2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))\u0026#39;, list(\u0026#39;NIR\u0026#39; = image$select(\u0026#34;B8\u0026#34;), \u0026#39;RED\u0026#39; = image$select(\u0026#34;B4\u0026#34;), \u0026#39;BLUE\u0026#39; = image$select(\u0026#34;B2\u0026#34;)) )$rename(\u0026#34;EVI\u0026#34;) return(image$addBands(evi)) }) evi_image \u0026lt;- s2_collection$select(\u0026#34;EVI\u0026#34;)$mean()$clip(aoi) First mapping of EVI This is to make sure the current values are correct and being visualized correctly. I had a lot of trouble with this example in particular, so I am redundantly checking work as we go.\nevi_viz \u0026lt;- list( min = -1, max = 1, palette = c(\u0026#34;brown\u0026#34;, \u0026#34;yellow\u0026#34;, \u0026#34;green\u0026#34;) ) Map$setCenter(-98.35, 38.5, 6) Map$addLayer(evi_image, evi_viz, \u0026#34;EVI\u0026#34;) Loading precip data We load precip data from TerraClimate, filter it for the year 2020, average values, and clip them.\nppt_dataset \u0026lt;- ee$ImageCollection(\u0026#34;IDAHO_EPSCOR/TERRACLIMATE\u0026#34;)$ filterDate(\u0026#39;2020-01-01\u0026#39;, \u0026#39;2020-12-31\u0026#39;)$ select(\u0026#34;pr\u0026#34;)$ mean()$ clip(aoi) Visualize PPT to make sure it\u0026rsquo;s correct Again, I am visualizing the precipitation data to make sure it looks correct.\nppt_viz \u0026lt;- list( min = 0, max = 2000, palette = c(\u0026#34;blue\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;green\u0026#34;) ) Map$addLayer(ppt_dataset, ppt_viz, \u0026#34;Precipitation\u0026#34;) Make sure data is aligned Before actually performing any operations on the data, making sure that both datasets are aligned correctly is important. Here I\u0026rsquo;m reprojecting both sets to the same scale and resolution.\nevi_resampled \u0026lt;- evi_image$reproject(crs = ppt_dataset$projection(), scale = 1000) ppt_resampled \u0026lt;- ppt_dataset$reproject(crs = evi_image$projection(), scale = 1000) Transform the data Dividing the EVI by the precip to calculate the ratio.\nevi_ppt_ratio \u0026lt;- evi_resampled$divide(ppt_resampled) Define viz params for mapping the new ratio evi_ppt_viz \u0026lt;- list( min = 0, max = 0.1, palette = c(\u0026#34;blue\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;red\u0026#34;) ) Map$addLayer(evi_ppt_ratio, evi_ppt_viz, \u0026#34;EVI/PPT Ratio\u0026#34;) ","permalink":"http://localhost:1313/posts/making-maps-of-variables-with-rgee/","summary":"Introduction Raw data often needs to be transformed in order to do anything useful with it. Typically, transforming variables in GEE involves manipulating raw bands of imagery to create products like NDVI and EVI, or performing math operations with multiple datasets.\nDividing EVI by Precipitation In this example, EVI is being divided by precipitation data for Kansas, and the result is mapped.\nLoad and initialize rgee first!\nlibrary(rgee) ee_Initialize() # Define an area of interest (AOI) over Kansas aoi \u0026lt;- ee$Geometry$Rectangle(c(-102.","title":"Making maps of variables with rgee"},{"content":"Introduction From the rgee github page: \u0026ldquo;rgee is an R binding package for calling Google Earth Engine API from within R. Various functions are implemented to simplify the connection with the R spatial ecosystem.\u0026rdquo;\nThis guide assumes use of RStudio on a Mac, but I personally use Emacs with ESS and found it to work wonderfully. Any Unix based system should work similarly. Windows should theoretically work by following the below, but more work might be required and I haven\u0026rsquo;t tested it.\nPrerequisites R and RStudio (or other IDE) Google Earth Engine account. Create a GEE project to work in. A healthy mindset 😊 Installation Install rgee, geojsonio and miniconda.\ninstall.packages(\u0026#39;rgee\u0026#39;) install.packages(\u0026#39;reticulate\u0026#39;) install.packages(\u0026#39;geojsonio\u0026#39;) reticulate::install_miniconda() Setup Load the packages.\nlibrary(rgee) library(geojsonio) library(reticulate) Install dependencies and double check to make sure everything is up to date.\nrgee::ee_install() rgee::ee_install_upgrade() By this point, you should be ready to initialize rgee. To double check everything is ready, run a\nee_check() to make sure. Note: If the previous command complains about an argument being of length zero, it should be fine to ignore it and carry on.\nInitializing If you haven\u0026rsquo;t already, you will need to create a new project to work in. This process is semi annoying if you haven\u0026rsquo;t already done it before, full disclaimer.\nNavigate over to the GEE code editor and click on your profile picture in the top right. Click \u0026ldquo;Register a new Cloud Project\u0026rdquo;. Assuming this is correct, click \u0026ldquo;Register a Noncommercial or Commercial project\u0026rdquo; and then select \u0026ldquo;Unpaid usage\u0026rdquo;. Select the relevent project type in the dropdown menu.\nOn the next screen, choose \u0026ldquo;Create a new Google Cloud Project\u0026rdquo;. You can leave the Organization field blank, but you will need to at the least choose a project ID. I usually name my projects with the ee-username-rgee-#, where username is my username and # is a number. Note that creating the project can take a while. Don\u0026rsquo;t refresh the page, as you will be forced to go through the above process again.\nOnce you\u0026rsquo;ve confirmed your project\u0026rsquo;s information, you will be redirected to the GEE online code editor, where you can close the tab.\nMoving back into the IDE, we can now initialize rgee.\nee_Initialize() This should launch a page in your web browser where you can log in and select the project you created to link to rgee. Make sure to choose \u0026ldquo;Select an existing project\u0026rdquo; and select it.\nIf that didn\u0026rsquo;t work, or threw you an error, don\u0026rsquo;t panic. I had enormous amounts of trouble getting rgee to initialize properly. If this is the case for you, you can instead run the below two commands, which does the same thing.\nNote that you will need to replace the project name with your own.\nee$Authenticate(auth_mode=\u0026#39;localhost\u0026#39;) ee$Initialize(project=\u0026#39;YOUR-PROJECT-NAME\u0026#39;) Optionally, check your connectivity to GEE to see if everything is setup correctly.\nee$String(\u0026#39;Hello from the Earth Engine servers!\u0026#39;)$getInfo() If one of those methods worked, pop the champagne.\nAt the start of every new R session where you want to use rgee, you will need to load and then initialize the package in order to use it.\nThis should look something like this\nlibrary(rgee) ee$Authenticate(auth_mode=\u0026#39;localhost\u0026#39;) ee$Initialize(project=\u0026#39;YOUR-PROJECT-NAME\u0026#39;) Remember to change the project name to the one you created earlier.\nExamples Surface water occurrence In this example, rgee is used to visualize global surface water occurrence using the JRC Global Surface Water dataset.\nLoad and initialize rgee first!\n# Loads the dataset from JRC gsw \u0026lt;- ee$Image(\u0026#34;JRC/GSW1_1/GlobalSurfaceWater\u0026#34;) occurrence \u0026lt;- gsw$select(\u0026#34;occurrence\u0026#34;) # Defines params to show surface water VIS_OCCURRENCE \u0026lt;- list( min = 0, max = 100, palette = c(\u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;) ) # Makes a mask with said params VIS_WATER_MASK \u0026lt;- list( palette = c(\u0026#34;white\u0026#34;, \u0026#34;black\u0026#34;) ) # Creates another mask that only shows areas w/ 90% water occurance water_mask \u0026lt;- occurrence$gt(90)$selfMask() # Sets the center of the map to Douglas County Map$setCenter(-95.3, 38.91, 11) # Adds both masks to the map Map$addLayer(occurrence$updateMask(occurrence$divide(100)), VIS_OCCURRENCE, \u0026#34;Water Occurrence (1984-2018)\u0026#34;) + Map$addLayer(water_mask, VIS_WATER_MASK, \u0026#34;90% occurrence\u0026#34;, FALSE) {% endhighlight %} May 28th 2019 Tornado In this example, rgee is used to view the damage path from the 2019 EF4 tornado that touched down in central Douglas County.\nLoad and initialize rgee first!\n# Defines an area around Douglas County. aoi \u0026lt;- ee$Geometry$Rectangle(c(-95.3, 38.85, -95.22, 38.91)) # Defines the dates we are interested in. start_date \u0026lt;- \u0026#39;2019-05-28\u0026#39; end_date \u0026lt;- \u0026#39;2019-06-01\u0026#39; pre_event_date \u0026lt;- \u0026#39;2019-05-20\u0026#39; # Load Sentinel-2 data for said dates. s2_collection \u0026lt;- ee$ImageCollection(\u0026#39;COPERNICUS/S2\u0026#39;)$ filterDate(start_date, end_date)$ filterBounds(aoi) # Get the least cloudy image from the post-event period. post_event_image \u0026lt;- s2_collection$sort(\u0026#39;CLOUDY_PIXEL_PERCENTAGE\u0026#39;)$first() # Define params for said image. viz_params \u0026lt;- list( bands = c(\u0026#39;B4\u0026#39;, \u0026#39;B3\u0026#39;, \u0026#39;B2\u0026#39;), min = 0, max = 3000, gamma = 1.4 ) # Add the post-event image to the map. Map$centerObject(aoi, 12) # Zoom in to level 12 for better detail Map$addLayer(post_event_image, viz_params, \u0026#39;Post-Event Sentinel-2 Image\u0026#39;) # Load pre-event data for comparison. pre_event_image \u0026lt;- ee$ImageCollection(\u0026#39;COPERNICUS/S2\u0026#39;)$ filterDate(pre_event_date, start_date)$ filterBounds(aoi)$ sort(\u0026#39;CLOUDY_PIXEL_PERCENTAGE\u0026#39;)$first() # Calculate NDVI for pre and post tornado. pre_ndvi \u0026lt;- pre_event_image$normalizedDifference(c(\u0026#39;B8\u0026#39;, \u0026#39;B4\u0026#39;)) post_ndvi \u0026lt;- post_event_image$normalizedDifference(c(\u0026#39;B8\u0026#39;, \u0026#39;B4\u0026#39;)) # Find difference. ndvi_diff \u0026lt;- post_ndvi$subtract(pre_ndvi) # Define params for NDVI difference. ndvi_viz_params \u0026lt;- list(min = -0.5, max = 0.5, palette = c(\u0026#39;red\u0026#39;, \u0026#39;yellow\u0026#39;, \u0026#39;green\u0026#39;)) # Add NDVI diff. layer to map! Map$addLayer(ndvi_diff, ndvi_viz_params, \u0026#39;NDVI Difference\u0026#39;) {% endhighlight %} ","permalink":"http://localhost:1313/posts/setting-up-rgee/","summary":"Introduction From the rgee github page: \u0026ldquo;rgee is an R binding package for calling Google Earth Engine API from within R. Various functions are implemented to simplify the connection with the R spatial ecosystem.\u0026rdquo;\nThis guide assumes use of RStudio on a Mac, but I personally use Emacs with ESS and found it to work wonderfully. Any Unix based system should work similarly. Windows should theoretically work by following the below, but more work might be required and I haven\u0026rsquo;t tested it.","title":"Setting up rgee"},{"content":"Introduction Google Earth Engine provides access to a bunch of geospatial datasets including satellite imagery, climate data and land cover classifications. These datasets, known as variables, are used to perform geospatial analyses.\nCalling variables Load and initialize rgee first!\nDefine an area that you want to visualize. The easiest way of doing this is to define a rectangle with coordinates.\naoi \u0026lt;- ee$Geometry$Rectangle(c(-120.4, 34.5, -119.4, 35.5)) In this example, I\u0026rsquo;ll use the MODIS land cover datasets.\nlandcover \u0026lt;- ee$ImageCollection(\u0026#34;MODIS/061/MCD12Q1\u0026#34;)$first()$select(\u0026#34;LC_Type1\u0026#34;) Set some visualization parameters to control how the data is displayed.\nlandcover_viz \u0026lt;- list( min = 1, max = 17, palette = c(\u0026#34;05450a\u0026#34;, \u0026#34;086a10\u0026#34;, \u0026#34;54a708\u0026#34;, \u0026#34;78d203\u0026#34;, \u0026#34;009900\u0026#34;, \u0026#34;c6b044\u0026#34;, \u0026#34;dcd159\u0026#34;, \u0026#34;dade48\u0026#34;, \u0026#34;fbff13\u0026#34;, \u0026#34;b6ff05\u0026#34;, \u0026#34;27ff87\u0026#34;, \u0026#34;c24f44\u0026#34;, \u0026#34;a5a5a5\u0026#34;, \u0026#34;ff6d4c\u0026#34;, \u0026#34;69fff8\u0026#34;, \u0026#34;f9ffa4\u0026#34;, \u0026#34;1c0dff\u0026#34;) ) Center the map on the area we are interested in, and add in the land cover layer using the parameters we defined above.\nMap$centerObject(aoi,8) Map$addLayer(landcover, landcover_viz, \u0026#34;Land Cover :)\u0026#34;) ","permalink":"http://localhost:1313/posts/using-variables-in-rgee/","summary":"Introduction Google Earth Engine provides access to a bunch of geospatial datasets including satellite imagery, climate data and land cover classifications. These datasets, known as variables, are used to perform geospatial analyses.\nCalling variables Load and initialize rgee first!\nDefine an area that you want to visualize. The easiest way of doing this is to define a rectangle with coordinates.\naoi \u0026lt;- ee$Geometry$Rectangle(c(-120.4, 34.5, -119.4, 35.5)) In this example, I\u0026rsquo;ll use the MODIS land cover datasets.","title":"Using variables in rgee"},{"content":"Introduction I set out with the goal to create documentation so that my process was both transparent and reproducible. While a word document probably would have sufficed, it simply would not have been as fun. Additionally, it seemed like anything I could publish to the web could be easily archived with something like the wayback machine and then could be easily referenced too without worrying about it\u0026rsquo;s longevity.\n","permalink":"http://localhost:1313/posts/creating-this-website/","summary":"Introduction I set out with the goal to create documentation so that my process was both transparent and reproducible. While a word document probably would have sufficed, it simply would not have been as fun. Additionally, it seemed like anything I could publish to the web could be easily archived with something like the wayback machine and then could be easily referenced too without worrying about it\u0026rsquo;s longevity.","title":"Creating this website"}]